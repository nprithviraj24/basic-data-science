{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Final Exam, Aug Semester, 2019\n",
    "\n",
    "In this exam, you will demonstrate your understanding of the material from the lectures, tutorials, and problem sets.\n",
    "\n",
    "For each question, insert your answer directly in this sheet. When complete, export the sheet as a PDF and upload to Gradescope.\n",
    "Note that you have **2.5 hours** to do the exam. Also note that there are some short answer questions that you may be able to answer faster than the coding questions. You might consider answering those questions first to get as much credit as possible!\n",
    "\n",
    "## Question 1 (10 points)\n",
    "\n",
    "Generate 200 2D points from each of 2 Guassians with distributions shaped roughly as shown in the diagram below, with class 1 as the 'X's and class 2 as the 'O's. Plot the resulting 400 points with different colors for each Gaussian.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.ones((200,1)).shape\n",
    "# np.array([y_c1]).T.shape\n",
    "# X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "mean1 = [2,3]; cov1 = [[0.5,0], [0,0.5]]\n",
    "x_c1, y_c1 = np.random.multivariate_normal(mean1, cov1, 200).T\n",
    "np.matrix([x_c1]).T.shape\n",
    "X1 = np.c_[np.ones((200,1)), np.array([x_c1]).T, np.array([y_c1]).T ]\n",
    "xx1 = np.c_[np.array([x_c1]).T, np.array([y_c1]).T]\n",
    "mean2 = [4,4]; cov2 = [[0.5,0], [0,0.5]]\n",
    "x_c2, y_c2 = np.random.multivariate_normal(mean2, cov2, 200).T\n",
    "X2 = np.c_[np.ones((200,1)), np.array([x_c2]).T, np.array([y_c2]).T ]\n",
    "\n",
    "xx2 = np.c_[np.array([x_c2]).T, np.array([y_c2]).T ]\n",
    "\n",
    "plt.plot(x_c1, y_c1, 'x')\n",
    "plt.plot(x_c2,y_c2, 'o')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "xx = np.r_[xx1, xx2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (20 points)\n",
    "\n",
    "Do the following:\n",
    "1. Split the dataset from Question 1 into a training set (80%) and validation set (20%).\n",
    "2. Fit a logistic regression model to the data in the training set.\n",
    "3. Indicate the training set accuracy and validation set accuracy of the logistic regression model.\n",
    "4. Make two separate plots, one for the training set and one for the validation set, with three colors: one for correctly classified points from class 1, one for correctly classified points from class 2, and one for incorrectly classified points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: parms (-4.000000, 0.000000, 1.000000), trn like -176.654413 acc 0.718750 test like -43.161979 acc 0.775000 *\n",
      "Iter 1: parms (-3.965891, 0.234370, 1.153142), trn like -156.061501 acc 0.721875 test like -38.098349 acc 0.762500 *\n",
      "Iter 2: parms (-4.013879, 0.197536, 1.010093), trn like -144.750195 acc 0.840625 test like -35.305502 acc 0.837500 *\n",
      "Iter 3: parms (-4.021846, 0.282489, 1.008418), trn like -139.656390 acc 0.831250 test like -33.974198 acc 0.837500 *\n",
      "Iter 4: parms (-4.045096, 0.314206, 0.952264), trn like -135.507516 acc 0.865625 test like -32.910471 acc 0.875000 *\n",
      "Iter 5: parms (-4.060451, 0.367036, 0.924469), trn like -131.884106 acc 0.878125 test like -31.950487 acc 0.887500 *\n",
      "Iter 6: parms (-4.078565, 0.407392, 0.887070), trn like -128.625371 acc 0.903125 test like -31.097542 acc 0.900000 *\n",
      "Iter 7: parms (-4.094825, 0.450159, 0.856539), trn like -125.673972 acc 0.909375 test like -30.313211 acc 0.925000 *\n",
      "Iter 8: parms (-4.111282, 0.489082, 0.825569), trn like -122.992968 acc 0.912500 test like -29.601146 acc 0.925000 *\n",
      "Iter 9: parms (-4.127119, 0.526954, 0.797072), trn like -120.552523 acc 0.915625 test like -28.947609 acc 0.937500 *\n",
      "Iter 10: parms (-4.142712, 0.562792, 0.769706), trn like -118.326728 acc 0.918750 test like -28.349068 acc 0.950000 *\n",
      "Iter 11: parms (-4.157948, 0.597137, 0.743869), trn like -116.292696 acc 0.925000 test like -27.798538 acc 0.950000 *\n",
      "Iter 12: parms (-4.172905, 0.629919, 0.719281), trn like -114.430179 acc 0.931250 test like -27.291534 acc 0.950000 *\n",
      "Iter 13: parms (-4.187585, 0.661295, 0.695929), trn like -112.721257 acc 0.934375 test like -26.823390 acc 0.950000 *\n",
      "Iter 14: parms (-4.202013, 0.691327, 0.673711), trn like -111.150079 acc 0.940625 test like -26.390262 acc 0.950000 *\n",
      "Iter 15: parms (-4.216205, 0.720103, 0.652564), trn like -109.702616 acc 0.943750 test like -25.988645 acc 0.950000 *\n",
      "Iter 16: parms (-4.230179, 0.747697, 0.632419), trn like -108.366450 acc 0.940625 test like -25.615479 acc 0.937500 *\n",
      "Iter 17: parms (-4.243948, 0.774178, 0.613215), trn like -107.130577 acc 0.943750 test like -25.268038 acc 0.950000 *\n",
      "Iter 18: parms (-4.257527, 0.799611, 0.594896), trn like -105.985239 acc 0.940625 test like -24.943908 acc 0.950000 *\n",
      "Iter 19: parms (-4.270928, 0.824056, 0.577409), trn like -104.921767 acc 0.943750 test like -24.640944 acc 0.962500 *\n",
      "Iter 20: parms (-4.284161, 0.847568, 0.560706), trn like -103.932453 acc 0.943750 test like -24.357239 acc 0.962500 *\n",
      "Iter 21: parms (-4.297238, 0.870199, 0.544742), trn like -103.010432 acc 0.943750 test like -24.091091 acc 0.950000 *\n",
      "Iter 22: parms (-4.310167, 0.891998, 0.529476), trn like -102.149579 acc 0.943750 test like -23.840982 acc 0.950000 *\n",
      "Iter 23: parms (-4.322957, 0.913008, 0.514868), trn like -101.344421 acc 0.946875 test like -23.605551 acc 0.950000 *\n",
      "Iter 24: parms (-4.335616, 0.933273, 0.500883), trn like -100.590061 acc 0.946875 test like -23.383581 acc 0.950000 *\n",
      "Iter 25: parms (-4.348151, 0.952829, 0.487487), trn like -99.882106 acc 0.943750 test like -23.173976 acc 0.950000 *\n",
      "Iter 26: parms (-4.360568, 0.971715, 0.474651), trn like -99.216612 acc 0.943750 test like -22.975752 acc 0.950000 *\n",
      "Iter 27: parms (-4.372875, 0.989962, 0.462344), trn like -98.590031 acc 0.946875 test like -22.788021 acc 0.950000 *\n",
      "Iter 28: parms (-4.385077, 1.007603, 0.450541), trn like -97.999165 acc 0.943750 test like -22.609979 acc 0.950000 *\n",
      "Iter 29: parms (-4.397178, 1.024668, 0.439215), trn like -97.441127 acc 0.943750 test like -22.440900 acc 0.950000 *\n",
      "Iter 30: parms (-4.409183, 1.041183, 0.428344), trn like -96.913308 acc 0.943750 test like -22.280126 acc 0.950000 *\n",
      "Iter 31: parms (-4.421098, 1.057174, 0.417906), trn like -96.413343 acc 0.940625 test like -22.127058 acc 0.950000 *\n",
      "Iter 32: parms (-4.432926, 1.072666, 0.407881), trn like -95.939090 acc 0.937500 test like -21.981152 acc 0.950000 *\n",
      "Iter 33: parms (-4.444672, 1.087682, 0.398248), trn like -95.488599 acc 0.937500 test like -21.841911 acc 0.950000 *\n",
      "Iter 34: parms (-4.456337, 1.102242, 0.388991), trn like -95.060100 acc 0.937500 test like -21.708882 acc 0.950000 *\n",
      "Iter 35: parms (-4.467927, 1.116366, 0.380092), trn like -94.651976 acc 0.937500 test like -21.581651 acc 0.950000 *\n",
      "Iter 36: parms (-4.479444, 1.130074, 0.371535), trn like -94.262754 acc 0.937500 test like -21.459838 acc 0.950000 *\n",
      "Iter 37: parms (-4.490891, 1.143384, 0.363306), trn like -93.891089 acc 0.934375 test like -21.343093 acc 0.950000 *\n",
      "Iter 38: parms (-4.502271, 1.156311, 0.355390), trn like -93.535747 acc 0.937500 test like -21.231098 acc 0.950000 *\n",
      "Iter 39: parms (-4.513585, 1.168872, 0.347773), trn like -93.195600 acc 0.937500 test like -21.123557 acc 0.950000 *\n",
      "Iter 40: parms (-4.524838, 1.181082, 0.340445), trn like -92.869611 acc 0.937500 test like -21.020199 acc 0.950000 *\n",
      "Iter 41: parms (-4.536030, 1.192955, 0.333392), trn like -92.556830 acc 0.937500 test like -20.920774 acc 0.950000 *\n",
      "Iter 42: parms (-4.547163, 1.204503, 0.326603), trn like -92.256381 acc 0.937500 test like -20.825049 acc 0.950000 *\n",
      "Iter 43: parms (-4.558241, 1.215741, 0.320068), trn like -91.967458 acc 0.934375 test like -20.732810 acc 0.950000 *\n",
      "Iter 44: parms (-4.569264, 1.226680, 0.313777), trn like -91.689320 acc 0.934375 test like -20.643859 acc 0.950000 *\n",
      "Iter 45: parms (-4.580235, 1.237330, 0.307720), trn like -91.421279 acc 0.934375 test like -20.558013 acc 0.950000 *\n",
      "Iter 46: parms (-4.591155, 1.247704, 0.301888), trn like -91.162703 acc 0.934375 test like -20.475099 acc 0.950000 *\n",
      "Iter 47: parms (-4.602025, 1.257811, 0.296273), trn like -90.913007 acc 0.934375 test like -20.394958 acc 0.950000 *\n",
      "Iter 48: parms (-4.612847, 1.267662, 0.290867), trn like -90.671648 acc 0.931250 test like -20.317444 acc 0.950000 *\n",
      "Iter 49: parms (-4.623622, 1.277264, 0.285661), trn like -90.438123 acc 0.931250 test like -20.242418 acc 0.950000 *\n",
      "Iter 50: parms (-4.634352, 1.286628, 0.280648), trn like -90.211966 acc 0.931250 test like -20.169751 acc 0.950000 *\n",
      "Iter 51: parms (-4.645038, 1.295762, 0.275822), trn like -89.992746 acc 0.931250 test like -20.099323 acc 0.950000 *\n",
      "Iter 52: parms (-4.655681, 1.304673, 0.271175), trn like -89.780059 acc 0.928125 test like -20.031023 acc 0.950000 *\n",
      "Iter 53: parms (-4.666282, 1.313369, 0.266701), trn like -89.573532 acc 0.925000 test like -19.964744 acc 0.950000 *\n",
      "Iter 54: parms (-4.676842, 1.321859, 0.262395), trn like -89.372816 acc 0.925000 test like -19.900388 acc 0.950000 *\n",
      "Iter 55: parms (-4.687362, 1.330148, 0.258250), trn like -89.177588 acc 0.925000 test like -19.837864 acc 0.950000 *\n",
      "Iter 56: parms (-4.697843, 1.338243, 0.254260), trn like -88.987545 acc 0.921875 test like -19.777085 acc 0.950000 *\n",
      "Iter 57: parms (-4.708286, 1.346151, 0.250421), trn like -88.802404 acc 0.921875 test like -19.717969 acc 0.950000 *\n",
      "Iter 58: parms (-4.718692, 1.353878, 0.246727), trn like -88.621902 acc 0.925000 test like -19.660440 acc 0.950000 *\n",
      "Iter 59: parms (-4.729061, 1.361429, 0.243174), trn like -88.445793 acc 0.925000 test like -19.604426 acc 0.950000 *\n",
      "Iter 60: parms (-4.739395, 1.368812, 0.239756), trn like -88.273847 acc 0.921875 test like -19.549860 acc 0.950000 *\n",
      "Iter 61: parms (-4.749694, 1.376029, 0.236470), trn like -88.105848 acc 0.921875 test like -19.496677 acc 0.950000 *\n",
      "Iter 62: parms (-4.759958, 1.383088, 0.233311), trn like -87.941595 acc 0.921875 test like -19.444818 acc 0.950000 *\n",
      "Iter 63: parms (-4.770189, 1.389993, 0.230275), trn like -87.780897 acc 0.918750 test like -19.394227 acc 0.950000 *\n",
      "Iter 64: parms (-4.780387, 1.396748, 0.227357), trn like -87.623578 acc 0.918750 test like -19.344848 acc 0.950000 *\n",
      "Iter 65: parms (-4.790552, 1.403358, 0.224555), trn like -87.469472 acc 0.915625 test like -19.296632 acc 0.950000 *\n",
      "Iter 66: parms (-4.800686, 1.409828, 0.221865), trn like -87.318422 acc 0.915625 test like -19.249532 acc 0.950000 *\n",
      "Iter 67: parms (-4.810789, 1.416162, 0.219282), trn like -87.170281 acc 0.915625 test like -19.203501 acc 0.950000 *\n",
      "Iter 68: parms (-4.820861, 1.422364, 0.216804), trn like -87.024911 acc 0.915625 test like -19.158496 acc 0.950000 *\n",
      "Iter 69: parms (-4.830903, 1.428437, 0.214428), trn like -86.882183 acc 0.915625 test like -19.114478 acc 0.950000 *\n",
      "Iter 70: parms (-4.840915, 1.434386, 0.212150), trn like -86.741975 acc 0.915625 test like -19.071407 acc 0.950000 *\n",
      "Iter 71: parms (-4.850898, 1.440214, 0.209967), trn like -86.604171 acc 0.915625 test like -19.029247 acc 0.950000 *\n",
      "Iter 72: parms (-4.860852, 1.445925, 0.207877), trn like -86.468663 acc 0.915625 test like -18.987964 acc 0.950000 *\n",
      "Iter 73: parms (-4.870778, 1.451522, 0.205876), trn like -86.335350 acc 0.915625 test like -18.947523 acc 0.950000 *\n",
      "Iter 74: parms (-4.880676, 1.457008, 0.203962), trn like -86.204134 acc 0.915625 test like -18.907895 acc 0.950000 *\n",
      "Iter 75: parms (-4.890547, 1.462386, 0.202133), trn like -86.074925 acc 0.912500 test like -18.869049 acc 0.950000 *\n",
      "Iter 76: parms (-4.900390, 1.467660, 0.200386), trn like -85.947637 acc 0.912500 test like -18.830956 acc 0.950000 *\n",
      "Iter 77: parms (-4.910207, 1.472832, 0.198718), trn like -85.822189 acc 0.912500 test like -18.793590 acc 0.950000 *\n",
      "Iter 78: parms (-4.919997, 1.477905, 0.197128), trn like -85.698505 acc 0.912500 test like -18.756926 acc 0.950000 *\n",
      "Iter 79: parms (-4.929761, 1.482882, 0.195613), trn like -85.576511 acc 0.912500 test like -18.720938 acc 0.950000 *\n",
      "Iter 80: parms (-4.939500, 1.487765, 0.194170), trn like -85.456141 acc 0.912500 test like -18.685603 acc 0.950000 *\n",
      "Iter 81: parms (-4.949213, 1.492557, 0.192798), trn like -85.337329 acc 0.912500 test like -18.650898 acc 0.950000 *\n",
      "Iter 82: parms (-4.958901, 1.497261, 0.191495), trn like -85.220013 acc 0.912500 test like -18.616804 acc 0.950000 *\n",
      "Iter 83: parms (-4.968564, 1.501878, 0.190258), trn like -85.104136 acc 0.912500 test like -18.583298 acc 0.950000 *\n",
      "Iter 84: parms (-4.978203, 1.506412, 0.189087), trn like -84.989642 acc 0.915625 test like -18.550363 acc 0.950000 *\n",
      "Iter 85: parms (-4.987818, 1.510863, 0.187979), trn like -84.876480 acc 0.915625 test like -18.517978 acc 0.950000 *\n",
      "Iter 86: parms (-4.997409, 1.515236, 0.186931), trn like -84.764600 acc 0.915625 test like -18.486127 acc 0.950000 *\n",
      "Iter 87: parms (-5.006976, 1.519530, 0.185944), trn like -84.653956 acc 0.915625 test like -18.454793 acc 0.950000 *\n",
      "Iter 88: parms (-5.016520, 1.523749, 0.185014), trn like -84.544502 acc 0.915625 test like -18.423959 acc 0.950000 *\n",
      "Iter 89: parms (-5.026040, 1.527895, 0.184141), trn like -84.436196 acc 0.915625 test like -18.393609 acc 0.950000 *\n",
      "Iter 90: parms (-5.035538, 1.531969, 0.183323), trn like -84.328998 acc 0.915625 test like -18.363729 acc 0.950000 *\n",
      "Iter 91: parms (-5.045012, 1.535973, 0.182558), trn like -84.222871 acc 0.915625 test like -18.334305 acc 0.950000 *\n",
      "Iter 92: parms (-5.054465, 1.539909, 0.181844), trn like -84.117778 acc 0.915625 test like -18.305322 acc 0.950000 *\n",
      "Iter 93: parms (-5.063895, 1.543778, 0.181182), trn like -84.013684 acc 0.918750 test like -18.276768 acc 0.950000 *\n",
      "Iter 94: parms (-5.073303, 1.547583, 0.180568), trn like -83.910556 acc 0.918750 test like -18.248629 acc 0.950000 *\n",
      "Iter 95: parms (-5.082689, 1.551324, 0.180002), trn like -83.808365 acc 0.918750 test like -18.220895 acc 0.950000 *\n",
      "Iter 96: parms (-5.092054, 1.555005, 0.179482), trn like -83.707079 acc 0.918750 test like -18.193553 acc 0.950000 *\n",
      "Iter 97: parms (-5.101397, 1.558625, 0.179008), trn like -83.606670 acc 0.918750 test like -18.166591 acc 0.950000 *\n",
      "Iter 98: parms (-5.110719, 1.562186, 0.178578), trn like -83.507113 acc 0.918750 test like -18.140000 acc 0.950000 *\n",
      "Iter 99: parms (-5.120020, 1.565691, 0.178190), trn like -83.408380 acc 0.918750 test like -18.113769 acc 0.950000 *\n",
      "Iter 100: parms (-5.129300, 1.569139, 0.177844), trn like -83.310447 acc 0.918750 test like -18.087888 acc 0.950000 *\n",
      "Iter 101: parms (-5.138559, 1.572533, 0.177539), trn like -83.213292 acc 0.918750 test like -18.062348 acc 0.950000 *\n",
      "Iter 102: parms (-5.147797, 1.575875, 0.177274), trn like -83.116892 acc 0.918750 test like -18.037139 acc 0.950000 *\n",
      "Iter 103: parms (-5.157016, 1.579164, 0.177047), trn like -83.021226 acc 0.918750 test like -18.012252 acc 0.950000 *\n",
      "Iter 104: parms (-5.166214, 1.582403, 0.176857), trn like -82.926272 acc 0.918750 test like -17.987680 acc 0.950000 *\n",
      "Iter 105: parms (-5.175392, 1.585592, 0.176704), trn like -82.832013 acc 0.918750 test like -17.963412 acc 0.950000 *\n",
      "Iter 106: parms (-5.184550, 1.588733, 0.176586), trn like -82.738430 acc 0.918750 test like -17.939443 acc 0.950000 *\n",
      "Iter 107: parms (-5.193688, 1.591827, 0.176503), trn like -82.645504 acc 0.918750 test like -17.915764 acc 0.950000 *\n",
      "Iter 108: parms (-5.202806, 1.594876, 0.176454), trn like -82.553220 acc 0.918750 test like -17.892368 acc 0.950000 *\n",
      "Iter 109: parms (-5.211906, 1.597879, 0.176438), trn like -82.461560 acc 0.918750 test like -17.869248 acc 0.950000 *\n",
      "Iter 110: parms (-5.220985, 1.600838, 0.176453), trn like -82.370510 acc 0.918750 test like -17.846396 acc 0.950000 *\n",
      "Iter 111: parms (-5.230046, 1.603755, 0.176500), trn like -82.280054 acc 0.918750 test like -17.823807 acc 0.950000 *\n",
      "Iter 112: parms (-5.239087, 1.606629, 0.176577), trn like -82.190179 acc 0.918750 test like -17.801474 acc 0.950000 *\n",
      "Iter 113: parms (-5.248110, 1.609463, 0.176684), trn like -82.100871 acc 0.918750 test like -17.779390 acc 0.950000 *\n",
      "Iter 114: parms (-5.257114, 1.612257, 0.176820), trn like -82.012116 acc 0.918750 test like -17.757550 acc 0.950000 *\n",
      "Iter 115: parms (-5.266099, 1.615011, 0.176983), trn like -81.923903 acc 0.918750 test like -17.735949 acc 0.950000 *\n",
      "Iter 116: parms (-5.275065, 1.617728, 0.177174), trn like -81.836220 acc 0.918750 test like -17.714579 acc 0.950000 *\n",
      "Iter 117: parms (-5.284014, 1.620407, 0.177392), trn like -81.749055 acc 0.918750 test like -17.693437 acc 0.950000 *\n",
      "Iter 118: parms (-5.292943, 1.623050, 0.177636), trn like -81.662397 acc 0.918750 test like -17.672517 acc 0.950000 *\n",
      "Iter 119: parms (-5.301855, 1.625657, 0.177905), trn like -81.576236 acc 0.918750 test like -17.651814 acc 0.950000 *\n",
      "Iter 120: parms (-5.310748, 1.628229, 0.178198), trn like -81.490561 acc 0.918750 test like -17.631323 acc 0.950000 *\n",
      "Iter 121: parms (-5.319624, 1.630767, 0.178516), trn like -81.405363 acc 0.918750 test like -17.611039 acc 0.950000 *\n",
      "Iter 122: parms (-5.328481, 1.633271, 0.178857), trn like -81.320632 acc 0.918750 test like -17.590959 acc 0.950000 *\n",
      "Iter 123: parms (-5.337321, 1.635744, 0.179221), trn like -81.236360 acc 0.918750 test like -17.571076 acc 0.950000 *\n",
      "Iter 124: parms (-5.346143, 1.638184, 0.179607), trn like -81.152538 acc 0.918750 test like -17.551388 acc 0.950000 *\n",
      "Iter 125: parms (-5.354948, 1.640593, 0.180015), trn like -81.069158 acc 0.918750 test like -17.531889 acc 0.950000 *\n",
      "Iter 126: parms (-5.363735, 1.642971, 0.180444), trn like -80.986211 acc 0.918750 test like -17.512577 acc 0.950000 *\n",
      "Iter 127: parms (-5.372505, 1.645320, 0.180894), trn like -80.903691 acc 0.918750 test like -17.493446 acc 0.950000 *\n",
      "Iter 128: parms (-5.381257, 1.647639, 0.181363), trn like -80.821589 acc 0.921875 test like -17.474494 acc 0.950000 *\n",
      "Iter 129: parms (-5.389992, 1.649930, 0.181853), trn like -80.739898 acc 0.921875 test like -17.455717 acc 0.950000 *\n",
      "Iter 130: parms (-5.398710, 1.652193, 0.182361), trn like -80.658613 acc 0.921875 test like -17.437111 acc 0.950000 *\n",
      "Iter 131: parms (-5.407412, 1.654428, 0.182888), trn like -80.577725 acc 0.921875 test like -17.418672 acc 0.950000 *\n",
      "Iter 132: parms (-5.416096, 1.656637, 0.183433), trn like -80.497229 acc 0.921875 test like -17.400398 acc 0.950000 *\n",
      "Iter 133: parms (-5.424764, 1.658820, 0.183995), trn like -80.417119 acc 0.921875 test like -17.382285 acc 0.950000 *\n",
      "Iter 134: parms (-5.433414, 1.660976, 0.184575), trn like -80.337389 acc 0.921875 test like -17.364329 acc 0.950000 *\n",
      "Iter 135: parms (-5.442049, 1.663108, 0.185172), trn like -80.258032 acc 0.921875 test like -17.346529 acc 0.950000 *\n",
      "Iter 136: parms (-5.450666, 1.665215, 0.185785), trn like -80.179044 acc 0.921875 test like -17.328880 acc 0.950000 *\n",
      "Iter 137: parms (-5.459267, 1.667298, 0.186414), trn like -80.100420 acc 0.921875 test like -17.311381 acc 0.950000 *\n",
      "Iter 138: parms (-5.467852, 1.669358, 0.187058), trn like -80.022153 acc 0.921875 test like -17.294028 acc 0.950000 *\n",
      "Iter 139: parms (-5.476421, 1.671394, 0.187718), trn like -79.944240 acc 0.921875 test like -17.276818 acc 0.950000 *\n",
      "Iter 140: parms (-5.484973, 1.673408, 0.188392), trn like -79.866674 acc 0.921875 test like -17.259750 acc 0.950000 *\n",
      "Iter 141: parms (-5.493509, 1.675400, 0.189081), trn like -79.789453 acc 0.921875 test like -17.242819 acc 0.950000 *\n",
      "Iter 142: parms (-5.502029, 1.677370, 0.189783), trn like -79.712570 acc 0.921875 test like -17.226025 acc 0.950000 *\n",
      "Iter 143: parms (-5.510533, 1.679319, 0.190499), trn like -79.636023 acc 0.921875 test like -17.209363 acc 0.950000 *\n",
      "Iter 144: parms (-5.519021, 1.681247, 0.191229), trn like -79.559805 acc 0.921875 test like -17.192833 acc 0.950000 *\n",
      "Iter 145: parms (-5.527494, 1.683155, 0.191971), trn like -79.483915 acc 0.921875 test like -17.176431 acc 0.950000 *\n",
      "Iter 146: parms (-5.535950, 1.685042, 0.192727), trn like -79.408347 acc 0.921875 test like -17.160156 acc 0.950000 *\n",
      "Iter 147: parms (-5.544391, 1.686911, 0.193494), trn like -79.333097 acc 0.921875 test like -17.144005 acc 0.950000 *\n",
      "Iter 148: parms (-5.552817, 1.688760, 0.194273), trn like -79.258163 acc 0.921875 test like -17.127977 acc 0.950000 *\n",
      "Iter 149: parms (-5.561226, 1.690590, 0.195064), trn like -79.183540 acc 0.921875 test like -17.112068 acc 0.950000 *\n",
      "Iter 150: parms (-5.569621, 1.692402, 0.195867), trn like -79.109225 acc 0.921875 test like -17.096278 acc 0.950000 *\n",
      "Iter 151: parms (-5.578000, 1.694196, 0.196680), trn like -79.035214 acc 0.921875 test like -17.080603 acc 0.950000 *\n",
      "Iter 152: parms (-5.586363, 1.695972, 0.197504), trn like -78.961505 acc 0.921875 test like -17.065043 acc 0.950000 *\n",
      "Iter 153: parms (-5.594712, 1.697731, 0.198339), trn like -78.888093 acc 0.921875 test like -17.049595 acc 0.950000 *\n",
      "Iter 154: parms (-5.603045, 1.699473, 0.199184), trn like -78.814976 acc 0.921875 test like -17.034257 acc 0.950000 *\n",
      "Iter 155: parms (-5.611363, 1.701198, 0.200039), trn like -78.742151 acc 0.921875 test like -17.019029 acc 0.950000 *\n",
      "Iter 156: parms (-5.619666, 1.702908, 0.200904), trn like -78.669615 acc 0.921875 test like -17.003907 acc 0.950000 *\n",
      "Iter 157: parms (-5.627954, 1.704601, 0.201778), trn like -78.597365 acc 0.921875 test like -16.988890 acc 0.950000 *\n",
      "Iter 158: parms (-5.636227, 1.706278, 0.202661), trn like -78.525398 acc 0.921875 test like -16.973978 acc 0.950000 *\n",
      "Iter 159: parms (-5.644485, 1.707940, 0.203553), trn like -78.453712 acc 0.921875 test like -16.959167 acc 0.950000 *\n",
      "Iter 160: parms (-5.652728, 1.709587, 0.204454), trn like -78.382303 acc 0.921875 test like -16.944457 acc 0.950000 *\n",
      "Iter 161: parms (-5.660957, 1.711220, 0.205363), trn like -78.311170 acc 0.921875 test like -16.929846 acc 0.950000 *\n",
      "Iter 162: parms (-5.669171, 1.712838, 0.206281), trn like -78.240309 acc 0.921875 test like -16.915332 acc 0.950000 *\n",
      "Iter 163: parms (-5.677370, 1.714441, 0.207206), trn like -78.169719 acc 0.921875 test like -16.900914 acc 0.950000 *\n",
      "Iter 164: parms (-5.685555, 1.716031, 0.208140), trn like -78.099397 acc 0.921875 test like -16.886591 acc 0.950000 *\n",
      "Iter 165: parms (-5.693725, 1.717607, 0.209081), trn like -78.029340 acc 0.921875 test like -16.872362 acc 0.950000 *\n",
      "Iter 166: parms (-5.701881, 1.719170, 0.210030), trn like -77.959546 acc 0.921875 test like -16.858224 acc 0.950000 *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 167: parms (-5.710023, 1.720719, 0.210985), trn like -77.890013 acc 0.921875 test like -16.844177 acc 0.950000 *\n",
      "Iter 168: parms (-5.718150, 1.722256, 0.211948), trn like -77.820739 acc 0.921875 test like -16.830218 acc 0.950000 *\n",
      "Iter 169: parms (-5.726263, 1.723780, 0.212917), trn like -77.751722 acc 0.921875 test like -16.816348 acc 0.950000 *\n",
      "Iter 170: parms (-5.734361, 1.725292, 0.213893), trn like -77.682960 acc 0.921875 test like -16.802565 acc 0.950000 *\n",
      "Iter 171: parms (-5.742446, 1.726791, 0.214876), trn like -77.614450 acc 0.921875 test like -16.788867 acc 0.950000 *\n",
      "Iter 172: parms (-5.750516, 1.728279, 0.215865), trn like -77.546190 acc 0.921875 test like -16.775254 acc 0.950000 *\n",
      "Iter 173: parms (-5.758572, 1.729755, 0.216860), trn like -77.478180 acc 0.921875 test like -16.761724 acc 0.950000 *\n",
      "Iter 174: parms (-5.766615, 1.731219, 0.217861), trn like -77.410416 acc 0.921875 test like -16.748276 acc 0.950000 *\n",
      "Iter 175: parms (-5.774643, 1.732672, 0.218867), trn like -77.342897 acc 0.921875 test like -16.734909 acc 0.950000 *\n",
      "Iter 176: parms (-5.782658, 1.734114, 0.219879), trn like -77.275621 acc 0.918750 test like -16.721622 acc 0.950000 *\n",
      "Iter 177: parms (-5.790658, 1.735546, 0.220897), trn like -77.208586 acc 0.921875 test like -16.708414 acc 0.950000 *\n",
      "Iter 178: parms (-5.798645, 1.736966, 0.221920), trn like -77.141790 acc 0.921875 test like -16.695284 acc 0.950000 *\n",
      "Iter 179: parms (-5.806619, 1.738376, 0.222948), trn like -77.075232 acc 0.921875 test like -16.682230 acc 0.950000 *\n",
      "Iter 180: parms (-5.814578, 1.739776, 0.223980), trn like -77.008911 acc 0.921875 test like -16.669253 acc 0.950000 *\n",
      "Iter 181: parms (-5.822524, 1.741166, 0.225018), trn like -76.942824 acc 0.921875 test like -16.656350 acc 0.950000 *\n",
      "Iter 182: parms (-5.830456, 1.742546, 0.226061), trn like -76.876969 acc 0.921875 test like -16.643521 acc 0.950000 *\n",
      "Iter 183: parms (-5.838375, 1.743916, 0.227108), trn like -76.811346 acc 0.921875 test like -16.630766 acc 0.950000 *\n",
      "Iter 184: parms (-5.846281, 1.745276, 0.228159), trn like -76.745952 acc 0.921875 test like -16.618082 acc 0.950000 *\n",
      "Iter 185: parms (-5.854172, 1.746627, 0.229215), trn like -76.680786 acc 0.921875 test like -16.605470 acc 0.950000 *\n",
      "Iter 186: parms (-5.862051, 1.747969, 0.230274), trn like -76.615847 acc 0.921875 test like -16.592928 acc 0.950000 *\n",
      "Iter 187: parms (-5.869916, 1.749302, 0.231338), trn like -76.551132 acc 0.921875 test like -16.580455 acc 0.950000 *\n",
      "Iter 188: parms (-5.877768, 1.750626, 0.232406), trn like -76.486642 acc 0.921875 test like -16.568051 acc 0.950000 *\n",
      "Iter 189: parms (-5.885607, 1.751942, 0.233477), trn like -76.422373 acc 0.921875 test like -16.555715 acc 0.950000 *\n",
      "Iter 190: parms (-5.893433, 1.753248, 0.234552), trn like -76.358325 acc 0.921875 test like -16.543446 acc 0.950000 *\n",
      "Iter 191: parms (-5.901245, 1.754547, 0.235631), trn like -76.294496 acc 0.921875 test like -16.531243 acc 0.950000 *\n",
      "Iter 192: parms (-5.909044, 1.755837, 0.236713), trn like -76.230885 acc 0.921875 test like -16.519106 acc 0.950000 *\n",
      "Iter 193: parms (-5.916831, 1.757119, 0.237798), trn like -76.167491 acc 0.921875 test like -16.507034 acc 0.950000 *\n",
      "Iter 194: parms (-5.924604, 1.758393, 0.238887), trn like -76.104312 acc 0.921875 test like -16.495025 acc 0.950000 *\n",
      "Iter 195: parms (-5.932364, 1.759659, 0.239978), trn like -76.041346 acc 0.921875 test like -16.483080 acc 0.950000 *\n",
      "Iter 196: parms (-5.940112, 1.760918, 0.241073), trn like -75.978594 acc 0.921875 test like -16.471197 acc 0.950000 *\n",
      "Iter 197: parms (-5.947846, 1.762169, 0.242171), trn like -75.916052 acc 0.921875 test like -16.459376 acc 0.950000 *\n",
      "Iter 198: parms (-5.955568, 1.763412, 0.243271), trn like -75.853721 acc 0.921875 test like -16.447617 acc 0.950000 *\n",
      "Iter 199: parms (-5.963277, 1.764648, 0.244374), trn like -75.791598 acc 0.921875 test like -16.435918 acc 0.950000 *\n",
      "Iter 200: parms (-5.970974, 1.765877, 0.245480), trn like -75.729683 acc 0.921875 test like -16.424278 acc 0.950000 *\n",
      "Iter 201: parms (-5.978657, 1.767099, 0.246588), trn like -75.667975 acc 0.921875 test like -16.412698 acc 0.950000 *\n",
      "Iter 202: parms (-5.986328, 1.768315, 0.247698), trn like -75.606471 acc 0.921875 test like -16.401177 acc 0.950000 *\n",
      "Iter 203: parms (-5.993987, 1.769523, 0.248811), trn like -75.545172 acc 0.921875 test like -16.389713 acc 0.950000 *\n",
      "Iter 204: parms (-6.001633, 1.770724, 0.249926), trn like -75.484075 acc 0.921875 test like -16.378307 acc 0.950000 *\n",
      "Iter 205: parms (-6.009266, 1.771919, 0.251044), trn like -75.423180 acc 0.921875 test like -16.366957 acc 0.950000 *\n",
      "Iter 206: parms (-6.016887, 1.773108, 0.252163), trn like -75.362486 acc 0.921875 test like -16.355664 acc 0.950000 *\n",
      "Iter 207: parms (-6.024496, 1.774290, 0.253284), trn like -75.301991 acc 0.921875 test like -16.344426 acc 0.950000 *\n",
      "Iter 208: parms (-6.032092, 1.775466, 0.254408), trn like -75.241694 acc 0.921875 test like -16.333243 acc 0.950000 *\n",
      "Iter 209: parms (-6.039676, 1.776635, 0.255533), trn like -75.181595 acc 0.918750 test like -16.322115 acc 0.950000 *\n",
      "Iter 210: parms (-6.047247, 1.777799, 0.256660), trn like -75.121692 acc 0.918750 test like -16.311040 acc 0.950000 *\n",
      "Iter 211: parms (-6.054807, 1.778957, 0.257788), trn like -75.061983 acc 0.918750 test like -16.300019 acc 0.950000 *\n",
      "Iter 212: parms (-6.062354, 1.780108, 0.258919), trn like -75.002469 acc 0.918750 test like -16.289051 acc 0.950000 *\n",
      "Iter 213: parms (-6.069889, 1.781254, 0.260050), trn like -74.943148 acc 0.918750 test like -16.278135 acc 0.950000 *\n",
      "Iter 214: parms (-6.077411, 1.782395, 0.261184), trn like -74.884019 acc 0.918750 test like -16.267271 acc 0.950000 *\n",
      "Iter 215: parms (-6.084922, 1.783530, 0.262318), trn like -74.825080 acc 0.918750 test like -16.256458 acc 0.950000 *\n",
      "Iter 216: parms (-6.092421, 1.784659, 0.263454), trn like -74.766332 acc 0.918750 test like -16.245695 acc 0.950000 *\n",
      "Iter 217: parms (-6.099907, 1.785783, 0.264592), trn like -74.707773 acc 0.918750 test like -16.234984 acc 0.950000 *\n",
      "Iter 218: parms (-6.107382, 1.786901, 0.265730), trn like -74.649401 acc 0.918750 test like -16.224322 acc 0.950000 *\n",
      "Iter 219: parms (-6.114845, 1.788015, 0.266870), trn like -74.591216 acc 0.918750 test like -16.213709 acc 0.950000 *\n",
      "Iter 220: parms (-6.122296, 1.789123, 0.268011), trn like -74.533218 acc 0.918750 test like -16.203145 acc 0.950000 *\n",
      "Iter 221: parms (-6.129735, 1.790226, 0.269152), trn like -74.475404 acc 0.918750 test like -16.192630 acc 0.950000 *\n",
      "Iter 222: parms (-6.137162, 1.791324, 0.270295), trn like -74.417775 acc 0.918750 test like -16.182163 acc 0.950000 *\n",
      "Iter 223: parms (-6.144577, 1.792418, 0.271439), trn like -74.360328 acc 0.918750 test like -16.171743 acc 0.950000 *\n",
      "Iter 224: parms (-6.151981, 1.793506, 0.272584), trn like -74.303064 acc 0.918750 test like -16.161370 acc 0.950000 *\n",
      "Iter 225: parms (-6.159373, 1.794590, 0.273729), trn like -74.245981 acc 0.918750 test like -16.151044 acc 0.950000 *\n",
      "Iter 226: parms (-6.166753, 1.795669, 0.274875), trn like -74.189079 acc 0.918750 test like -16.140765 acc 0.950000 *\n",
      "Iter 227: parms (-6.174122, 1.796744, 0.276022), trn like -74.132356 acc 0.918750 test like -16.130531 acc 0.950000 *\n",
      "Iter 228: parms (-6.181479, 1.797813, 0.277170), trn like -74.075811 acc 0.918750 test like -16.120343 acc 0.950000 *\n",
      "Iter 229: parms (-6.188825, 1.798879, 0.278318), trn like -74.019445 acc 0.918750 test like -16.110200 acc 0.950000 *\n",
      "Iter 230: parms (-6.196159, 1.799940, 0.279467), trn like -73.963255 acc 0.918750 test like -16.100101 acc 0.950000 *\n",
      "Iter 231: parms (-6.203481, 1.800997, 0.280616), trn like -73.907241 acc 0.918750 test like -16.090047 acc 0.950000 *\n",
      "Iter 232: parms (-6.210793, 1.802049, 0.281766), trn like -73.851402 acc 0.915625 test like -16.080037 acc 0.950000 *\n",
      "Iter 233: parms (-6.218092, 1.803098, 0.282916), trn like -73.795737 acc 0.915625 test like -16.070070 acc 0.950000 *\n",
      "Iter 234: parms (-6.225381, 1.804142, 0.284067), trn like -73.740245 acc 0.915625 test like -16.060147 acc 0.950000 *\n",
      "Iter 235: parms (-6.232658, 1.805182, 0.285218), trn like -73.684927 acc 0.915625 test like -16.050266 acc 0.950000 *\n",
      "Iter 236: parms (-6.239923, 1.806218, 0.286369), trn like -73.629779 acc 0.915625 test like -16.040428 acc 0.950000 *\n",
      "Iter 237: parms (-6.247178, 1.807250, 0.287520), trn like -73.574803 acc 0.915625 test like -16.030631 acc 0.950000 *\n",
      "Iter 238: parms (-6.254421, 1.808278, 0.288672), trn like -73.519997 acc 0.915625 test like -16.020877 acc 0.950000 *\n",
      "Iter 239: parms (-6.261653, 1.809303, 0.289824), trn like -73.465360 acc 0.915625 test like -16.011164 acc 0.950000 *\n",
      "Iter 240: parms (-6.268874, 1.810323, 0.290976), trn like -73.410891 acc 0.915625 test like -16.001492 acc 0.950000 *\n",
      "Iter 241: parms (-6.276084, 1.811340, 0.292128), trn like -73.356590 acc 0.918750 test like -15.991861 acc 0.950000 *\n",
      "Iter 242: parms (-6.283283, 1.812353, 0.293280), trn like -73.302456 acc 0.918750 test like -15.982270 acc 0.950000 *\n",
      "Iter 243: parms (-6.290470, 1.813363, 0.294433), trn like -73.248487 acc 0.918750 test like -15.972720 acc 0.950000 *\n",
      "Iter 244: parms (-6.297647, 1.814369, 0.295585), trn like -73.194684 acc 0.918750 test like -15.963209 acc 0.950000 *\n",
      "Iter 245: parms (-6.304813, 1.815372, 0.296737), trn like -73.141046 acc 0.918750 test like -15.953738 acc 0.950000 *\n",
      "Iter 246: parms (-6.311967, 1.816371, 0.297889), trn like -73.087571 acc 0.918750 test like -15.944305 acc 0.950000 *\n",
      "Iter 247: parms (-6.319111, 1.817366, 0.299041), trn like -73.034259 acc 0.918750 test like -15.934912 acc 0.950000 *\n",
      "Iter 248: parms (-6.326244, 1.818359, 0.300193), trn like -72.981110 acc 0.918750 test like -15.925557 acc 0.950000 *\n",
      "Iter 249: parms (-6.333366, 1.819348, 0.301345), trn like -72.928121 acc 0.915625 test like -15.916241 acc 0.950000 *\n",
      "Iter 250: parms (-6.340478, 1.820333, 0.302497), trn like -72.875294 acc 0.915625 test like -15.906962 acc 0.950000 *\n",
      "Iter 251: parms (-6.347578, 1.821316, 0.303648), trn like -72.822626 acc 0.915625 test like -15.897722 acc 0.950000 *\n",
      "Iter 252: parms (-6.354668, 1.822295, 0.304799), trn like -72.770118 acc 0.915625 test like -15.888518 acc 0.950000 *\n",
      "Iter 253: parms (-6.361747, 1.823271, 0.305950), trn like -72.717768 acc 0.915625 test like -15.879352 acc 0.950000 *\n",
      "Iter 254: parms (-6.368815, 1.824244, 0.307101), trn like -72.665575 acc 0.915625 test like -15.870222 acc 0.950000 *\n",
      "Iter 255: parms (-6.375873, 1.825214, 0.308251), trn like -72.613540 acc 0.915625 test like -15.861130 acc 0.950000 *\n",
      "Iter 256: parms (-6.382920, 1.826181, 0.309401), trn like -72.561661 acc 0.915625 test like -15.852073 acc 0.950000 *\n",
      "Iter 257: parms (-6.389956, 1.827145, 0.310550), trn like -72.509938 acc 0.915625 test like -15.843053 acc 0.950000 *\n",
      "Iter 258: parms (-6.396982, 1.828106, 0.311699), trn like -72.458369 acc 0.915625 test like -15.834068 acc 0.950000 *\n",
      "Iter 259: parms (-6.403997, 1.829064, 0.312848), trn like -72.406955 acc 0.915625 test like -15.825119 acc 0.950000 *\n",
      "Iter 260: parms (-6.411002, 1.830020, 0.313996), trn like -72.355694 acc 0.915625 test like -15.816205 acc 0.950000 *\n",
      "Iter 261: parms (-6.417997, 1.830972, 0.315144), trn like -72.304586 acc 0.915625 test like -15.807326 acc 0.950000 *\n",
      "Iter 262: parms (-6.424981, 1.831922, 0.316291), trn like -72.253630 acc 0.915625 test like -15.798482 acc 0.950000 *\n",
      "Iter 263: parms (-6.431954, 1.832869, 0.317437), trn like -72.202826 acc 0.915625 test like -15.789672 acc 0.950000 *\n",
      "Iter 264: parms (-6.438917, 1.833813, 0.318584), trn like -72.152172 acc 0.915625 test like -15.780897 acc 0.950000 *\n",
      "Iter 265: parms (-6.445870, 1.834755, 0.319729), trn like -72.101668 acc 0.915625 test like -15.772156 acc 0.950000 *\n",
      "Iter 266: parms (-6.452813, 1.835694, 0.320874), trn like -72.051314 acc 0.915625 test like -15.763448 acc 0.950000 *\n",
      "Iter 267: parms (-6.459745, 1.836630, 0.322018), trn like -72.001108 acc 0.915625 test like -15.754774 acc 0.950000 *\n",
      "Iter 268: parms (-6.466667, 1.837564, 0.323162), trn like -71.951051 acc 0.915625 test like -15.746134 acc 0.950000 *\n",
      "Iter 269: parms (-6.473579, 1.838495, 0.324305), trn like -71.901141 acc 0.915625 test like -15.737527 acc 0.950000 *\n",
      "Iter 270: parms (-6.480481, 1.839424, 0.325448), trn like -71.851378 acc 0.915625 test like -15.728952 acc 0.950000 *\n",
      "Iter 271: parms (-6.487372, 1.840350, 0.326589), trn like -71.801761 acc 0.915625 test like -15.720410 acc 0.950000 *\n",
      "Iter 272: parms (-6.494253, 1.841273, 0.327730), trn like -71.752289 acc 0.915625 test like -15.711901 acc 0.950000 *\n",
      "Iter 273: parms (-6.501125, 1.842195, 0.328871), trn like -71.702962 acc 0.915625 test like -15.703424 acc 0.950000 *\n",
      "Iter 274: parms (-6.507986, 1.843114, 0.330010), trn like -71.653780 acc 0.915625 test like -15.694979 acc 0.950000 *\n",
      "Iter 275: parms (-6.514837, 1.844030, 0.331149), trn like -71.604740 acc 0.915625 test like -15.686566 acc 0.950000 *\n",
      "Iter 276: parms (-6.521678, 1.844945, 0.332287), trn like -71.555844 acc 0.915625 test like -15.678184 acc 0.950000 *\n",
      "Iter 277: parms (-6.528509, 1.845857, 0.333424), trn like -71.507091 acc 0.915625 test like -15.669834 acc 0.950000 *\n",
      "Iter 278: parms (-6.535330, 1.846766, 0.334561), trn like -71.458479 acc 0.915625 test like -15.661515 acc 0.950000 *\n",
      "Iter 279: parms (-6.542142, 1.847674, 0.335696), trn like -71.410008 acc 0.915625 test like -15.653227 acc 0.950000 *\n",
      "Iter 280: parms (-6.548943, 1.848579, 0.336831), trn like -71.361677 acc 0.915625 test like -15.644970 acc 0.950000 *\n",
      "Iter 281: parms (-6.555734, 1.849482, 0.337965), trn like -71.313487 acc 0.915625 test like -15.636743 acc 0.950000 *\n",
      "Iter 282: parms (-6.562516, 1.850383, 0.339098), trn like -71.265435 acc 0.915625 test like -15.628547 acc 0.950000 *\n",
      "Iter 283: parms (-6.569288, 1.851281, 0.340230), trn like -71.217523 acc 0.915625 test like -15.620381 acc 0.950000 *\n",
      "Iter 284: parms (-6.576050, 1.852178, 0.341362), trn like -71.169748 acc 0.915625 test like -15.612245 acc 0.950000 *\n",
      "Iter 285: parms (-6.582802, 1.853072, 0.342492), trn like -71.122111 acc 0.915625 test like -15.604139 acc 0.950000 *\n",
      "Iter 286: parms (-6.589545, 1.853965, 0.343622), trn like -71.074611 acc 0.915625 test like -15.596063 acc 0.950000 *\n",
      "Iter 287: parms (-6.596278, 1.854855, 0.344750), trn like -71.027247 acc 0.915625 test like -15.588016 acc 0.950000 *\n",
      "Iter 288: parms (-6.603001, 1.855743, 0.345878), trn like -70.980019 acc 0.915625 test like -15.579998 acc 0.950000 *\n",
      "Iter 289: parms (-6.609714, 1.856629, 0.347005), trn like -70.932926 acc 0.915625 test like -15.572010 acc 0.950000 *\n",
      "Iter 290: parms (-6.616418, 1.857514, 0.348131), trn like -70.885967 acc 0.915625 test like -15.564050 acc 0.950000 *\n",
      "Iter 291: parms (-6.623113, 1.858396, 0.349255), trn like -70.839143 acc 0.915625 test like -15.556120 acc 0.950000 *\n",
      "Iter 292: parms (-6.629797, 1.859276, 0.350379), trn like -70.792452 acc 0.915625 test like -15.548217 acc 0.950000 *\n",
      "Iter 293: parms (-6.636473, 1.860155, 0.351502), trn like -70.745894 acc 0.915625 test like -15.540344 acc 0.950000 *\n",
      "Iter 294: parms (-6.643138, 1.861032, 0.352624), trn like -70.699468 acc 0.915625 test like -15.532498 acc 0.950000 *\n",
      "Iter 295: parms (-6.649795, 1.861906, 0.353745), trn like -70.653174 acc 0.915625 test like -15.524681 acc 0.950000 *\n",
      "Iter 296: parms (-6.656441, 1.862779, 0.354865), trn like -70.607011 acc 0.915625 test like -15.516891 acc 0.950000 *\n",
      "Iter 297: parms (-6.663079, 1.863650, 0.355983), trn like -70.560979 acc 0.915625 test like -15.509130 acc 0.950000 *\n",
      "Iter 298: parms (-6.669707, 1.864519, 0.357101), trn like -70.515077 acc 0.915625 test like -15.501395 acc 0.950000 *\n",
      "Iter 299: parms (-6.676325, 1.865386, 0.358218), trn like -70.469304 acc 0.915625 test like -15.493689 acc 0.950000 *\n",
      "Iter 300: parms (-6.682935, 1.866252, 0.359333), trn like -70.423660 acc 0.915625 test like -15.486009 acc 0.950000 *\n",
      "Iter 301: parms (-6.689534, 1.867116, 0.360448), trn like -70.378145 acc 0.915625 test like -15.478357 acc 0.950000 *\n",
      "Iter 302: parms (-6.696125, 1.867978, 0.361562), trn like -70.332758 acc 0.915625 test like -15.470731 acc 0.950000 *\n",
      "Iter 303: parms (-6.702706, 1.868838, 0.362674), trn like -70.287498 acc 0.915625 test like -15.463133 acc 0.950000 *\n",
      "Iter 304: parms (-6.709278, 1.869697, 0.363785), trn like -70.242365 acc 0.915625 test like -15.455561 acc 0.950000 *\n",
      "Iter 305: parms (-6.715841, 1.870554, 0.364896), trn like -70.197358 acc 0.915625 test like -15.448015 acc 0.950000 *\n",
      "Iter 306: parms (-6.722395, 1.871409, 0.366005), trn like -70.152477 acc 0.915625 test like -15.440496 acc 0.950000 *\n",
      "Iter 307: parms (-6.728940, 1.872262, 0.367113), trn like -70.107722 acc 0.915625 test like -15.433003 acc 0.950000 *\n",
      "Iter 308: parms (-6.735475, 1.873114, 0.368220), trn like -70.063091 acc 0.915625 test like -15.425536 acc 0.950000 *\n",
      "Iter 309: parms (-6.742001, 1.873965, 0.369325), trn like -70.018584 acc 0.918750 test like -15.418095 acc 0.950000 *\n",
      "Iter 310: parms (-6.748518, 1.874813, 0.370430), trn like -69.974201 acc 0.918750 test like -15.410680 acc 0.950000 *\n",
      "Iter 311: parms (-6.755026, 1.875660, 0.371534), trn like -69.929942 acc 0.918750 test like -15.403291 acc 0.950000 *\n",
      "Iter 312: parms (-6.761525, 1.876506, 0.372636), trn like -69.885805 acc 0.918750 test like -15.395926 acc 0.950000 *\n",
      "Iter 313: parms (-6.768015, 1.877350, 0.373737), trn like -69.841790 acc 0.921875 test like -15.388588 acc 0.950000 *\n",
      "Iter 314: parms (-6.774496, 1.878192, 0.374838), trn like -69.797897 acc 0.921875 test like -15.381274 acc 0.950000 *\n",
      "Iter 315: parms (-6.780968, 1.879033, 0.375936), trn like -69.754125 acc 0.921875 test like -15.373985 acc 0.950000 *\n",
      "Iter 316: parms (-6.787432, 1.879872, 0.377034), trn like -69.710474 acc 0.921875 test like -15.366722 acc 0.950000 *\n",
      "Iter 317: parms (-6.793886, 1.880710, 0.378131), trn like -69.666944 acc 0.921875 test like -15.359483 acc 0.950000 *\n",
      "Iter 318: parms (-6.800331, 1.881546, 0.379226), trn like -69.623532 acc 0.921875 test like -15.352269 acc 0.950000 *\n",
      "Iter 319: parms (-6.806767, 1.882381, 0.380321), trn like -69.580241 acc 0.921875 test like -15.345079 acc 0.950000 *\n",
      "Iter 320: parms (-6.813195, 1.883214, 0.381414), trn like -69.537068 acc 0.921875 test like -15.337914 acc 0.950000 *\n",
      "Iter 321: parms (-6.819614, 1.884046, 0.382506), trn like -69.494013 acc 0.921875 test like -15.330773 acc 0.950000 *\n",
      "Iter 322: parms (-6.826024, 1.884876, 0.383596), trn like -69.451076 acc 0.921875 test like -15.323656 acc 0.950000 *\n",
      "Iter 323: parms (-6.832425, 1.885705, 0.384686), trn like -69.408256 acc 0.921875 test like -15.316563 acc 0.950000 *\n",
      "Iter 324: parms (-6.838817, 1.886532, 0.385774), trn like -69.365553 acc 0.921875 test like -15.309494 acc 0.950000 *\n",
      "Iter 325: parms (-6.845201, 1.887358, 0.386861), trn like -69.322967 acc 0.921875 test like -15.302449 acc 0.950000 *\n",
      "Iter 326: parms (-6.851576, 1.888183, 0.387947), trn like -69.280496 acc 0.921875 test like -15.295427 acc 0.950000 *\n",
      "Iter 327: parms (-6.857942, 1.889006, 0.389032), trn like -69.238141 acc 0.921875 test like -15.288429 acc 0.950000 *\n",
      "Iter 328: parms (-6.864300, 1.889828, 0.390116), trn like -69.195901 acc 0.921875 test like -15.281455 acc 0.950000 *\n",
      "Iter 329: parms (-6.870649, 1.890649, 0.391198), trn like -69.153775 acc 0.921875 test like -15.274503 acc 0.950000 *\n",
      "Iter 330: parms (-6.876989, 1.891468, 0.392279), trn like -69.111764 acc 0.921875 test like -15.267575 acc 0.950000 *\n",
      "Iter 331: parms (-6.883321, 1.892286, 0.393359), trn like -69.069866 acc 0.921875 test like -15.260670 acc 0.950000 *\n",
      "Iter 332: parms (-6.889644, 1.893102, 0.394437), trn like -69.028081 acc 0.921875 test like -15.253787 acc 0.950000 *\n",
      "Iter 333: parms (-6.895959, 1.893917, 0.395515), trn like -68.986409 acc 0.921875 test like -15.246928 acc 0.950000 *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 334: parms (-6.902265, 1.894731, 0.396591), trn like -68.944849 acc 0.921875 test like -15.240091 acc 0.950000 *\n",
      "Iter 335: parms (-6.908563, 1.895544, 0.397666), trn like -68.903401 acc 0.921875 test like -15.233276 acc 0.950000 *\n",
      "Iter 336: parms (-6.914852, 1.896355, 0.398740), trn like -68.862064 acc 0.921875 test like -15.226485 acc 0.950000 *\n",
      "Iter 337: parms (-6.921132, 1.897165, 0.399812), trn like -68.820838 acc 0.921875 test like -15.219715 acc 0.950000 *\n",
      "Iter 338: parms (-6.927405, 1.897973, 0.400883), trn like -68.779723 acc 0.921875 test like -15.212968 acc 0.950000 *\n",
      "Iter 339: parms (-6.933669, 1.898781, 0.401953), trn like -68.738717 acc 0.921875 test like -15.206242 acc 0.950000 *\n",
      "Iter 340: parms (-6.939924, 1.899587, 0.403022), trn like -68.697822 acc 0.921875 test like -15.199539 acc 0.950000 *\n",
      "Iter 341: parms (-6.946171, 1.900392, 0.404090), trn like -68.657035 acc 0.921875 test like -15.192858 acc 0.950000 *\n",
      "Iter 342: parms (-6.952410, 1.901196, 0.405156), trn like -68.616357 acc 0.921875 test like -15.186198 acc 0.950000 *\n",
      "Iter 343: parms (-6.958640, 1.901998, 0.406221), trn like -68.575787 acc 0.921875 test like -15.179560 acc 0.950000 *\n",
      "Iter 344: parms (-6.964862, 1.902799, 0.407285), trn like -68.535326 acc 0.921875 test like -15.172944 acc 0.950000 *\n",
      "Iter 345: parms (-6.971076, 1.903599, 0.408347), trn like -68.494971 acc 0.925000 test like -15.166349 acc 0.950000 *\n",
      "Iter 346: parms (-6.977282, 1.904398, 0.409409), trn like -68.454724 acc 0.925000 test like -15.159776 acc 0.950000 *\n",
      "Iter 347: parms (-6.983479, 1.905196, 0.410469), trn like -68.414583 acc 0.925000 test like -15.153224 acc 0.950000 *\n",
      "Iter 348: parms (-6.989669, 1.905992, 0.411527), trn like -68.374549 acc 0.925000 test like -15.146693 acc 0.950000 *\n",
      "Iter 349: parms (-6.995849, 1.906787, 0.412585), trn like -68.334620 acc 0.925000 test like -15.140183 acc 0.950000 *\n",
      "Iter 350: parms (-7.002022, 1.907581, 0.413641), trn like -68.294797 acc 0.925000 test like -15.133693 acc 0.950000 *\n",
      "Iter 351: parms (-7.008187, 1.908374, 0.414696), trn like -68.255078 acc 0.925000 test like -15.127225 acc 0.950000 *\n",
      "Iter 352: parms (-7.014343, 1.909166, 0.415750), trn like -68.215464 acc 0.925000 test like -15.120778 acc 0.950000 *\n",
      "Iter 353: parms (-7.020492, 1.909957, 0.416802), trn like -68.175955 acc 0.925000 test like -15.114351 acc 0.950000 *\n",
      "Iter 354: parms (-7.026632, 1.910746, 0.417854), trn like -68.136548 acc 0.925000 test like -15.107945 acc 0.950000 *\n",
      "Iter 355: parms (-7.032764, 1.911534, 0.418904), trn like -68.097246 acc 0.925000 test like -15.101559 acc 0.950000 *\n",
      "Iter 356: parms (-7.038889, 1.912322, 0.419952), trn like -68.058046 acc 0.925000 test like -15.095193 acc 0.950000 *\n",
      "Iter 357: parms (-7.045005, 1.913108, 0.421000), trn like -68.018949 acc 0.925000 test like -15.088848 acc 0.950000 *\n",
      "Iter 358: parms (-7.051113, 1.913893, 0.422046), trn like -67.979953 acc 0.925000 test like -15.082523 acc 0.950000 *\n",
      "Iter 359: parms (-7.057213, 1.914677, 0.423091), trn like -67.941060 acc 0.925000 test like -15.076218 acc 0.950000 *\n",
      "Iter 360: parms (-7.063306, 1.915459, 0.424134), trn like -67.902268 acc 0.925000 test like -15.069933 acc 0.950000 *\n",
      "Iter 361: parms (-7.069390, 1.916241, 0.425177), trn like -67.863577 acc 0.925000 test like -15.063668 acc 0.950000 *\n",
      "Iter 362: parms (-7.075466, 1.917022, 0.426218), trn like -67.824986 acc 0.925000 test like -15.057423 acc 0.950000 *\n",
      "Iter 363: parms (-7.081535, 1.917801, 0.427258), trn like -67.786495 acc 0.925000 test like -15.051197 acc 0.950000 *\n",
      "Iter 364: parms (-7.087595, 1.918580, 0.428296), trn like -67.748105 acc 0.925000 test like -15.044991 acc 0.950000 *\n",
      "Iter 365: parms (-7.093648, 1.919357, 0.429334), trn like -67.709814 acc 0.925000 test like -15.038805 acc 0.950000 *\n",
      "Iter 366: parms (-7.099693, 1.920133, 0.430370), trn like -67.671621 acc 0.925000 test like -15.032638 acc 0.950000 *\n",
      "Iter 367: parms (-7.105730, 1.920909, 0.431405), trn like -67.633528 acc 0.925000 test like -15.026490 acc 0.950000 *\n",
      "Iter 368: parms (-7.111759, 1.921683, 0.432438), trn like -67.595532 acc 0.925000 test like -15.020361 acc 0.950000 *\n",
      "Iter 369: parms (-7.117781, 1.922456, 0.433470), trn like -67.557635 acc 0.925000 test like -15.014252 acc 0.950000 *\n",
      "Iter 370: parms (-7.123795, 1.923228, 0.434501), trn like -67.519835 acc 0.925000 test like -15.008162 acc 0.950000 *\n",
      "Iter 371: parms (-7.129801, 1.924000, 0.435531), trn like -67.482132 acc 0.925000 test like -15.002091 acc 0.950000 *\n",
      "Iter 372: parms (-7.135799, 1.924770, 0.436560), trn like -67.444526 acc 0.925000 test like -14.996038 acc 0.950000 *\n",
      "Iter 373: parms (-7.141789, 1.925539, 0.437587), trn like -67.407016 acc 0.925000 test like -14.990005 acc 0.950000 *\n",
      "Iter 374: parms (-7.147772, 1.926307, 0.438613), trn like -67.369603 acc 0.925000 test like -14.983990 acc 0.950000 *\n",
      "Iter 375: parms (-7.153747, 1.927074, 0.439638), trn like -67.332285 acc 0.925000 test like -14.977994 acc 0.950000 *\n",
      "Iter 376: parms (-7.159715, 1.927840, 0.440661), trn like -67.295062 acc 0.925000 test like -14.972016 acc 0.950000 *\n",
      "Iter 377: parms (-7.165675, 1.928605, 0.441683), trn like -67.257934 acc 0.925000 test like -14.966057 acc 0.950000 *\n",
      "Iter 378: parms (-7.171627, 1.929370, 0.442704), trn like -67.220901 acc 0.925000 test like -14.960117 acc 0.950000 *\n",
      "Iter 379: parms (-7.177572, 1.930133, 0.443724), trn like -67.183963 acc 0.925000 test like -14.954194 acc 0.950000 *\n",
      "Iter 380: parms (-7.183509, 1.930895, 0.444742), trn like -67.147118 acc 0.925000 test like -14.948290 acc 0.950000 *\n",
      "Iter 381: parms (-7.189439, 1.931656, 0.445759), trn like -67.110366 acc 0.925000 test like -14.942404 acc 0.950000 *\n",
      "Iter 382: parms (-7.195361, 1.932416, 0.446775), trn like -67.073708 acc 0.925000 test like -14.936536 acc 0.950000 *\n",
      "Iter 383: parms (-7.201276, 1.933176, 0.447790), trn like -67.037142 acc 0.925000 test like -14.930686 acc 0.950000 *\n",
      "Iter 384: parms (-7.207183, 1.933934, 0.448803), trn like -67.000670 acc 0.925000 test like -14.924855 acc 0.950000 *\n",
      "Iter 385: parms (-7.213082, 1.934691, 0.449815), trn like -66.964289 acc 0.925000 test like -14.919040 acc 0.950000 *\n",
      "Iter 386: parms (-7.218975, 1.935448, 0.450826), trn like -66.928000 acc 0.925000 test like -14.913244 acc 0.950000 *\n",
      "Iter 387: parms (-7.224859, 1.936203, 0.451836), trn like -66.891802 acc 0.925000 test like -14.907465 acc 0.950000 *\n",
      "Iter 388: parms (-7.230737, 1.936958, 0.452844), trn like -66.855696 acc 0.925000 test like -14.901704 acc 0.950000 *\n",
      "Iter 389: parms (-7.236607, 1.937711, 0.453852), trn like -66.819680 acc 0.925000 test like -14.895961 acc 0.950000 *\n",
      "Iter 390: parms (-7.242469, 1.938464, 0.454857), trn like -66.783755 acc 0.921875 test like -14.890235 acc 0.950000 *\n",
      "Iter 391: parms (-7.248324, 1.939216, 0.455862), trn like -66.747919 acc 0.921875 test like -14.884526 acc 0.950000 *\n",
      "Iter 392: parms (-7.254172, 1.939967, 0.456866), trn like -66.712174 acc 0.921875 test like -14.878835 acc 0.950000 *\n",
      "Iter 393: parms (-7.260013, 1.940717, 0.457868), trn like -66.676518 acc 0.921875 test like -14.873160 acc 0.950000 *\n",
      "Iter 394: parms (-7.265846, 1.941466, 0.458869), trn like -66.640951 acc 0.921875 test like -14.867503 acc 0.950000 *\n",
      "Iter 395: parms (-7.271672, 1.942214, 0.459868), trn like -66.605473 acc 0.921875 test like -14.861863 acc 0.950000 *\n",
      "Iter 396: parms (-7.277490, 1.942961, 0.460867), trn like -66.570083 acc 0.921875 test like -14.856241 acc 0.950000 *\n",
      "Iter 397: parms (-7.283302, 1.943707, 0.461864), trn like -66.534781 acc 0.921875 test like -14.850635 acc 0.950000 *\n",
      "Iter 398: parms (-7.289106, 1.944453, 0.462860), trn like -66.499568 acc 0.921875 test like -14.845045 acc 0.950000 *\n",
      "Iter 399: parms (-7.294903, 1.945197, 0.463855), trn like -66.464441 acc 0.921875 test like -14.839473 acc 0.950000 *\n"
     ]
    }
   ],
   "source": [
    "X1_train = X1[0:160,:]\n",
    "X1_test = X1[160:,:]\n",
    "X2_train = X2[0:160,:]\n",
    "X2_test = X2[160:,:]\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.concatenate((X1_train, X2_train), 0)\n",
    "y_train = np.concatenate((np.zeros((160,1)), np.ones((160,1))), 0)\n",
    "X_test = np.concatenate((X1_test, X2_test), 0)\n",
    "y_test = np.concatenate((np.zeros((40,1)), np.ones((40,1))), 0)\n",
    "\n",
    "def predict(X, theta):\n",
    "    return 1 / (1 + np.exp(- X @ theta))\n",
    "\n",
    "def loglike(y, ypred):\n",
    "    return sum(y * np.log(ypred) + (1-y) * np.log(1-ypred))[0]\n",
    "\n",
    "def accuracy(y, ypred):\n",
    "    return sum((ypred >= 0.5) == (y == 1)) / y.size\n",
    "    \n",
    "test_idx_0 = (y_test==0).reshape(X_test.shape[0])\n",
    "test_idx_1 = (y_test==1).reshape(X_test.shape[0])\n",
    "\n",
    "# correctOnes = \n",
    "# plt.plot()\n",
    "\n",
    "\n",
    "theta = np.array([[-4,0,1]]).T\n",
    "theta_best = theta\n",
    "loglike_test_best = 0\n",
    "alpha = 0.001\n",
    "for i in range(0,400):\n",
    "    ypred_train = predict(X_train, theta)\n",
    "    loglike_train = loglike(y_train, ypred_train)\n",
    "    acc_train = accuracy(y_train, ypred_train)\n",
    "    ypred_test = predict(X_test, theta)\n",
    "    loglike_test = loglike(y_test, ypred_test)\n",
    "    acc_test = accuracy(y_test, ypred_test)\n",
    "    sbest = ''\n",
    "    if i == 0 or loglike_test > loglike_test_best:\n",
    "        loglike_test_best = loglike_test\n",
    "        theta_best = theta\n",
    "        sbest = '*'\n",
    "    print('Iter %d: parms (%f, %f, %f), trn like %f acc %f test like %f acc %f %s' %\n",
    "          (i, theta[0], theta[1], theta[2], loglike_train, acc_train, loglike_test, acc_test, sbest))\n",
    "    dtheta = X_train.T @ (y_train - ypred_train)\n",
    "    theta = theta + alpha * dtheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: (-7.294903, 1.945197, 0.463855)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_line(plot_handle, theta):\n",
    "    X11 = -3.5\n",
    "    X12 = (- theta[0] - theta[1] * X11) / theta[2]\n",
    "    X21 = 3.5\n",
    "    X22 = (- theta[0] - theta[1] * X21) / theta[2]\n",
    "    plot_handle.plot([X11, X21], [X21, X22], 'k-')\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(X_test[test_idx_0, 1], X_test[test_idx_0, 2], 'ro', label='Class 1')\n",
    "plt.plot(X_test[test_idx_1, 1], X_test[test_idx_1, 2], 'bo', label='Class 2')\n",
    "plot_line(plt, theta_best)\n",
    "plt.xlim([-3.5,3.5])\n",
    "plt.legend()\n",
    "plt.title('Best logistic regression classifier')\n",
    "\n",
    "print('Best parameters: (%f, %f, %f)' % (theta_best[0], theta_best[1], theta_best[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (20 points)\n",
    "\n",
    "Do the following:\n",
    "1. Use the SVM code developed in class to fit linear SVMs to the training data from Question 2. Use several different values of hyperparameter c (the tolerance to points crossing the hyperplane), and plot validation set accuracy as a function of c.\n",
    "2. Explain which model is best and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = np.concatenate([np.matrix(np.zeros([200,1])),np.matrix(np.ones([200,1]))]);\n",
    "xx_train, xx_test, yy_train, yy_test = train_test_split(xx, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X = np.concatenate((X1, X2), 0)\n",
    "X = np.matrix(X)\n",
    "print(X.shape)\n",
    "y = np.matrix([np.r_[np.zeros((200)), np.ones((200))]])\n",
    "model = SVC(kernel='linear', C = 1E343)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prithvi/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model.fit(xx,y.T)\n",
    "\n",
    "##This takes a lot of time to code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.support_vectors_)\n",
    "# predict = model.predict(xx_test)\n",
    "plt.scatter(xx[:,0], xx[:, 1], c=y.reshape(400,), s=50, cmap='winter')\n",
    "plt.scatter(model.support_vectors_[:,0],model.support_vectors_[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cvxopt_solve_qp(Q, c, A=None, b=None, E=None, d=None):\n",
    "    Q = .5 * (Q + Q.T)  # make sure Q is symmetric\n",
    "    args = [cvxopt.matrix(Q), cvxopt.matrix(c)]\n",
    "    if A is not None:\n",
    "        args.extend([cvxopt.matrix(A), cvxopt.matrix(b)])\n",
    "        if E is not None:\n",
    "            args.extend([cvxopt.matrix(E), cvxopt.matrix(d)])\n",
    "    sol = cvxopt.solvers.qp(*args)\n",
    "    if 'optimal' not in sol['status']:\n",
    "        return None\n",
    "    return np.array(sol['x']).reshape((Q.shape[1],))\n",
    "\n",
    "X = np.concatenate((X1, X2), 0)\n",
    "X = np.matrix(X)\n",
    "type(X)\n",
    "\n",
    "y = np.concatenate((-np.ones((200,1)), np.ones((200,1))), 0)\n",
    "\n",
    "m = X.shape[0];\n",
    "n = X.shape[1];\n",
    "\n",
    "# Transform data set so that each attribute has a\n",
    "# mean of 0 and a standard deviation of 1\n",
    "\n",
    "def preprocess(X):\n",
    "    means = X.mean(0);\n",
    "    scales = 1/np.std(X,0);\n",
    "    Xh = np.concatenate([X.T,np.ones([1,20])],0);\n",
    "    Tm = np.matrix(np.eye(3));\n",
    "    Tm[0:2,2:3] = -X.mean(0).T;\n",
    "    Ts = np.matrix(np.eye(3));\n",
    "    Ts[0:2,0:2] = np.diagflat(scales);\n",
    "    T = Ts*Tm;\n",
    "    XX = (T * Xh);\n",
    "    XX = XX[0:2,:].T;\n",
    "    return XX, T;\n",
    "\n",
    "# RBF/Gaussian kernel\n",
    "\n",
    "def gauss_kernel(X):\n",
    "    sigma = 0.2\n",
    "    m = X.shape[0];\n",
    "    K = np.matrix(np.zeros([m,m]));\n",
    "    for i in range(0,m):\n",
    "        for j in range(0,m):\n",
    "            K[i,j] = (X[i,:] - X[j,:]) * (X[i,:] - X[j,:]).T\n",
    "    K = np.exp(-K/(2*sigma*sigma))      \n",
    "    return K;\n",
    "\n",
    "def linear_kernel(X):\n",
    "    m = X.shape[0];\n",
    "    K = np.matrix(np.zeros([m,m]));\n",
    "    for i in range(0,m):\n",
    "        for j in range(0,m):\n",
    "            K[i,j] = X[i,:]*(X[j,:].T)\n",
    "    return K;\n",
    "\n",
    "# Linear kernel below. We might also try\n",
    "# XX, T = preprocess(X)\n",
    "# K = gauss_kernel(XX)\n",
    "#print(X)\n",
    "K = linear_kernel(X);\n",
    "#print(K)\n",
    "Q = np.multiply(y * y.T, K)\n",
    "print('Q rank: %d' % np.linalg.matrix_rank(Q))\n",
    "c = -np.ones([m]);\n",
    "A = -np.eye(m);\n",
    "b = np.zeros([m]);\n",
    "E = y.T;\n",
    "d = np.zeros(1);\n",
    "alpha_star = cvxopt_solve_qp(Q, c, A, b, E, d);\n",
    "print(\"Optimal alpha:\")\n",
    "print(alpha_star)\n",
    "\n",
    "def get_wb(X, y, alpha):\n",
    "    # Find the support vectors\n",
    "    S = alpha > 1e-6 #threshold\n",
    "    XS = X[S,:]\n",
    "    yS = y[S]\n",
    "    alphaS = alpha[S]\n",
    "    alphaSyS = np.tile(np.multiply(yS.T, alphaS).T, n)\n",
    "    w = sum(np.multiply(alphaSyS, XS)).T\n",
    "    # Find b\n",
    "    KS = K[S,:][:,S]\n",
    "    NS = yS.shape[0]\n",
    "    b = (np.sum(yS) - np.sum(np.multiply(alphaS,yS.T)*KS))/NS\n",
    "    # Normalize w,b\n",
    "    scalef = np.linalg.norm(w)\n",
    "    w = w / scalef\n",
    "    b = b / scalef\n",
    "    return w,b\n",
    "\n",
    "w,b = get_wb(X, y, alpha_star)\n",
    "\n",
    "print(\"Optimal w: [%f,%f] b: %f\" % (w[0],w[1],b))\n",
    "plot_mf(Xf,Xm)\n",
    "\n",
    "def plot_w(w,b):\n",
    "    ylim = plt.axes().get_ylim()\n",
    "    xlim = plt.axes().get_xlim()\n",
    "    p1 = (xlim[0], - (w[0,0] * xlim[0] + b) / w[1,0])\n",
    "    p2 = (xlim[1], - (w[0,0] * xlim[1] + b) / w[1,0])\n",
    "    plt.plot((p1[0],p2[0]), (p1[1],p2[1]), 'r-')\n",
    "\n",
    "plot_w(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "\n",
    "Do the following:\n",
    "1. Use the SVM code developed in class to fit SVMs with the RBF kernel to the training data from Question 2. Use several different values of hyperparameter c (the tolerance to points crossing the hyperplane) and gamma (the basis function width), and plot validation set accuracy as a function of c and gamma.\n",
    "2. Explain which model is best and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# xx_train, xx_test, yy_train, yy_test = train_test_split(xx, y.T, test_size=0.2, random_state=42)\n",
    "\n",
    "# model2 = SVC(kernel='rbf', C = 1E343)\n",
    "# plt.scatter(xx_train[:,0], xx_train[:, 1], c=y.reshape(400,), s=50, cmap='winter')\n",
    "# plt.scatter(model2.support_vectors_[:,0],model2.support_vectors_[:,1])\n",
    "# model2.fit(xx_train,yy_train)\n",
    "# y_pred = model2.predict(xx_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Using the neural network code you developed (based on the code from class) for the deep learning homework assignment, do the following:\n",
    "1. Fit a two-layer neural network with ReLU activations in the hidden layer and a logistic output layer to the training data from Question 2. Use several different numbers of hidden units in the hidden layer, and plot validation set accuracy as a function of the number of units in the hidden layer.\n",
    "2. Explain which neural network is best and why, and briefly compare the neural network to the logistic regression and SVM models developed in the previous questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prithvi/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "xx_train = X_train\n",
    "y = np.matrix([np.r_[np.zeros((200)), np.ones((200))]])\n",
    "# #-----------------------------------------------------------------------\n",
    "M = 400\n",
    "N = 2\n",
    "\n",
    "def act(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def actder(z):\n",
    "    az = act(z)\n",
    "    prod = np.multiply(az,1-az)\n",
    "    return prod\n",
    "\n",
    "def ff(x,W,b):\n",
    "    L = len(W)-1\n",
    "    a = x\n",
    "    for l in range(1,L+1):\n",
    "        z = W[l].T*a+b[l]\n",
    "        a = act(z)\n",
    "    return a\n",
    "\n",
    "def loss(y,yhat):\n",
    "    return -((1-y) * np.log(1-yhat) + y * np.log(yhat))\n",
    "\n",
    "\n",
    "# Normalize each input feature\n",
    "\n",
    "def normalize(X):\n",
    "    M = X.shape[0]\n",
    "    # XX = X - mean of features of X\n",
    "    XX = X - np.tile(np.mean(X,0),[M,1])\n",
    "    # Divide each element of XX by std of X\n",
    "    XX = np.divide(XX, np.tile(np.std(XX,0),[M,1]))\n",
    "    \n",
    "    XX_new = np.divide(X, np.tile(np.std(XX,0),[M,1]))\n",
    "    return XX, XX_new\n",
    "\n",
    "XX, XX_new = normalize(xx_train)\n",
    "\n",
    "y = y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,8) (8,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a84dd7166d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# Just to give arrays the right shape for the backprop step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,8) (8,2) "
     ]
    }
   ],
   "source": [
    "# Initialize weights for units in each layer\n",
    "\n",
    "\n",
    "h2 = 10\n",
    "h1 = 8\n",
    "# h3 = 6\n",
    "# h4 = 3\n",
    "# Initialize weights for units in each layer\n",
    "W = [[], np.random.normal(0,0.1,[N,h1]),\n",
    "         np.random.normal(0,0.1,[h1,h2]),\n",
    "#          np.random.normal(0,0.1,[h2,h3]),\n",
    "#          np.random.normal(0,0.1,[h3,h4]),\n",
    "         np.random.normal(0,0.1,[h2,1])]\n",
    "\n",
    "b = [[], np.random.normal(0,0.1,[h1,1]),\n",
    "         np.random.normal(0,0.1,[h2,1]),\n",
    "#          np.random.normal(0,0.1,[h3,1]),\n",
    "#          np.random.normal(0,0.1,[h4,1]),\n",
    "         np.random.normal(0,0.1,[1,1])]\n",
    "\n",
    "L = len(W)-1\n",
    "# Use mini-batch size 1\n",
    "\n",
    "alpha = 0.001\n",
    "max_iter = 200\n",
    "loss_NN = []\n",
    "for iter in range(0, max_iter):\n",
    "    loss_this_iter = 0\n",
    "    order = np.random.permutation(M)   \n",
    "    #order = np.arange(0, M, 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0,M):\n",
    "        \n",
    "        # Grab the pattern order[i]\n",
    "        \n",
    "        x_this = xx[order[i],:].T\n",
    "        y_this = y[order[i],0]\n",
    "        #fig1 = plt.figure(figsize=(5,5)) \n",
    "        #ax = plt.axes() \n",
    "        #ax.set_aspect(aspect = 'equal', adjustable = 'box')\n",
    "        #plt.title('Pattern')\n",
    "        #plt.grid(axis='both', alpha=.25)\n",
    "        #plt.plot(XX[order][:,0], XX[order][:,1],'--')\n",
    "        #plt.show()\n",
    "        \n",
    "        # Feed forward step\n",
    "        \n",
    "        a = [x_this]\n",
    "        z = [[]]\n",
    "        delta = [[]]\n",
    "        dW = [[]]\n",
    "        db = [[]]\n",
    "        for l in range(1,L+1):\n",
    "            z.append(W[l].T*a[l-1]+b[l])\n",
    "            a.append(act(z[l]))\n",
    "            # Just to give arrays the right shape for the backprop step\n",
    "            delta.append([]); dW.append([]); db.append([])\n",
    "            \n",
    "        loss_this_pattern = loss(y_this, a[L][0,0])\n",
    "        loss_this_iter = loss_this_iter + loss_this_pattern\n",
    "        \n",
    "        # Backprop step\n",
    "\n",
    "        delta[L] = a[L] - y_this\n",
    "        for l in range(L,0,-1):\n",
    "            db[l] = delta[l].copy()\n",
    "            dW[l] = a[l-1] * delta[l].T\n",
    "            if l > 1:\n",
    "                delta[l-1] = np.multiply(actder(z[l-1]), W[l] *\n",
    "                             delta[l])\n",
    "                \n",
    "        # Check delta calculation        \n",
    "        if False:\n",
    "            print('Target: %f' % y_this)\n",
    "            print('y_hat: %f' % a[L][0,0])\n",
    "            print(db)\n",
    "            y_pred = ff(x_this,W,b)\n",
    "            diff = 1e-3\n",
    "            W[1][10,0] = W[1][10,0] + diff\n",
    "            y_pred_db = ff(x_this,W,b)\n",
    "            L1 = loss(y_this,y_pred)\n",
    "            L2 = loss(y_this,y_pred_db)\n",
    "            db_finite_difference = (L2-L1)/diff\n",
    "            print('Original out %f, perturbed out %f' %\n",
    "                 (y_pred[0,0], y_pred_db[0,0]))\n",
    "            print('Theoretical dW %f, calculated db %f' %\n",
    "                  (dW[1][10,0], db_finite_difference[0,0]))\n",
    "        \n",
    "        for l in range(1,L+1):            \n",
    "            W[l] = W[l] - alpha * dW[l]\n",
    "            b[l] = b[l] - alpha * db[l]\n",
    "        \n",
    "    #print('Iteration %d loss_train %f' % (iter, loss_this_iter))\n",
    "    loss_NN.append(loss_this_iter)\n",
    "fig3 = plt.figure(figsize=(5,5)) \n",
    "ax = plt.axes() \n",
    "plt.title('Iteration vs loss - Train')\n",
    "plt.plot(np.arange(0, max_iter),loss_NN,'g-' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ans2\n",
    "nd with number of units, more number of units have yielded more accuracy. So by rule of thumb I will prefer more number of units in each layer.\n",
    "After playing arou\n",
    "\n",
    "Neural networks are better models as they are computationally faster, and more accurate. Also tailoring each feature is not necesaary in contrast to shallow models where each feature needs to selected and feeded to the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (10 points)\n",
    "\n",
    "Consider what would happen if you got the data from Question 1 *without labels* and were tasked with using unsupervised learning to model and understand the data set. Based on a quick visualization, you see that there seem to be two main clusters in the data and decide to build a $k$-means ($k$=2) or GMM for the dataset.\n",
    "\n",
    "Obviously, a GMM would be appropriate, as the data were generated from a mixture of Gaussians in the first place. On the other hand, the $k$-means model would be simpler. Would it be as effective?\n",
    "\n",
    "Do the following:\n",
    "1. Write the parameters $\\phi_1$, $\\phi_2$, $\\mathbf{\\mu}_1$, $\\mathbf{\\mu}_2$, $\\mathtt{\\Sigma}_1$, $\\mathtt{\\Sigma}_2$ of the \"ground truth\" model used to generate the data in Question 1.\n",
    "2. Briefly discuss whether, in practice, the $k$-means model would be worse than, equally good, or better than a GMM for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth means and covariances for the data sets we'll generate\n",
    "phi_gt = [ 0.5, 0.5 ] # Since both are equally dense\n",
    "\n",
    "means_gt = [ [2,3], [4,4] ] # mu1 followed by mu2\n",
    "sigmas_gt = [ np.matrix([[0.5, 0],[0, 0.5]]), np.matrix([[0.5,0],[0,0.5]])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ans2:\n",
    "In practice, both are equally good. As each method's negative outweigh each other.\n",
    "\n",
    "Generally GMM is chosen as the go-to solution in these set of problems, but k-means stands a chance only because the distributions are spherical or circular in this case.\n",
    "\n",
    "K-means: \n",
    "- K-means are meant to be best when the clusters are spherical in nature, as there clusters are close to circular, because covariance matrix has 0 on non-diagnol elements.\n",
    "Negatives: It will classify the 'o' point that is close to 'x' as 'x'\n",
    "Similar either way as they form to gather the closest cluster.\n",
    "\n",
    "GMM:\n",
    "- Gaussian mixture model gives out the weight matrix or membership of each point to different Gaussian distributions in the space.\n",
    "Similar to the previous case, the point 'o' that is close to mean of 'x' will probably have higher probability than mean with 'o'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
