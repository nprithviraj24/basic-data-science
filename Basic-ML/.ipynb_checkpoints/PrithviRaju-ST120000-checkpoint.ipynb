{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Midterm, Aug Semester, 2019\n",
    "\n",
    "In this exam, you will demonstrate your understanding of the material from the lectures, tutorials, and problem sets.\n",
    "\n",
    "For each question, insert your answer directly in this sheet. When complete, export the sheet as a PDF and upload to Gradescope.\n",
    "\n",
    "Note that you have **2.5 hours** to do the exam. Also note that there is at least one short answer question that you may be able to answer faster than the coding questions. You might consider answering those questions first to get as much credit as possible!\n",
    "\n",
    "## Question 1 (20 points)\n",
    "\n",
    "Suppose you enjoy running for exercise, have great data science skills, and would like to build tools to help runners train effectively. You would like to predict a runner's future performance based on his or her past performances, and perhaps come up with some analytics about his or her fitness (increasing, decreasing, etc.)\n",
    "\n",
    "Consider the training and testing data given in the cell below. The data are measurements of Matt's runs from mid June to mid September 2019. The $\\mathtt{X}$ data contain variables for pace, distance, average temperature, and the number of hours of rest since the last run. The $\\mathbf{y}$ data are the average heart rate in beats per minute over each run. These data come from Garmin and OpenWeatherMap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Columns:\n",
    "# 0: average pace in minutes per kilometer\n",
    "# 1: distance in meters\n",
    "# 2: avg apparent temperature (Farenheight, includes humidity factor etc.)\n",
    "# 3: number of hours of rest since the last run\n",
    "\n",
    "Xtrain = np.array(\n",
    "      [[5.6041250e+00, 1.0386240e+04, 9.6480003e+01, 1.6693195e+02],\n",
    "       [4.5901036e+00, 3.3501699e+03, 9.0070000e+01, 1.4042222e+01],\n",
    "       [5.5853438e+00, 1.0589420e+04, 9.6894997e+01, 4.9480556e+01],\n",
    "       [8.4602365e+00, 5.2353198e+03, 9.2915001e+01, 4.8527222e+01],\n",
    "       [5.2759314e+00, 1.0260830e+04, 8.0415001e+01, 6.9376945e+01],\n",
    "       [5.0050054e+00, 1.0308060e+04, 7.8995003e+01, 7.2154442e+01],\n",
    "       [5.1679587e+00, 1.0297140e+04, 8.4269997e+01, 2.4243610e+01],\n",
    "       [5.5909653e+00, 1.6628650e+04, 9.5754997e+01, 5.8910278e+01],\n",
    "       [5.3112388e+00, 1.0397030e+04, 9.1875000e+01, 1.2679722e+01],\n",
    "       [5.0704794e+00, 1.0266610e+04, 8.7489998e+01, 4.8466110e+01],\n",
    "       [5.1297836e+00, 8.6998496e+03, 8.6510002e+01, 4.7598888e+01],\n",
    "       [5.8092251e+00, 2.1145150e+04, 9.6199997e+01, 5.9379166e+01],\n",
    "       [5.1203279e+00, 1.0201160e+04, 9.2875000e+01, 8.4886391e+01],\n",
    "       [5.1424460e+00, 1.0161310e+04, 8.9500000e+01, 2.3730000e+01],\n",
    "       [5.9502554e+00, 2.4152381e+04, 8.7389999e+01, 5.9973331e+01],\n",
    "       [5.4752522e+00, 1.2884080e+04, 9.2269997e+01, 3.6443890e+01],\n",
    "       [6.2727389e+00, 6.8037402e+03, 9.0209999e+01, 2.3653889e+01],\n",
    "       [5.6941118e+00, 1.6106010e+04, 8.7489998e+01, 2.4058611e+01],\n",
    "       [5.6941118e+00, 8.0607300e+03, 9.0735001e+01, 5.0604721e+01],\n",
    "       [5.1313629e+00, 1.4493960e+04, 9.4910004e+01, 2.3852777e+01],\n",
    "       [5.8397570e+00, 6.4594302e+03, 9.5209999e+01, 1.5108278e+02],\n",
    "       [6.0342746e+00, 2.1100061e+04, 9.2345001e+01, 1.9518888e+01],\n",
    "       [5.7790108e+00, 1.4495710e+04, 8.3410004e+01, 6.7106941e+01],\n",
    "       [5.4059896e+00, 1.6109050e+04, 8.6989998e+01, 2.4075834e+01],\n",
    "       [8.1819668e+00, 6.5416201e+03, 8.1650002e+01, 2.3606112e+01],\n",
    "       [5.6230321e+00, 8.0613101e+03, 9.4324997e+01, 2.5450277e+01],\n",
    "       [5.9101658e+00, 2.4156170e+04, 9.1650002e+01, 3.4091110e+01],\n",
    "       [5.1313629e+00, 1.4496380e+04, 8.9084999e+01, 3.6194443e+01],\n",
    "       [5.6650805e+00, 8.0576001e+03, 8.5985001e+01, 2.3728056e+01],\n",
    "       [5.7991180e+00, 1.6350690e+04, 8.9775002e+01, 4.7979168e+01],\n",
    "       [5.8234339e+00, 8.0631299e+03, 9.4845001e+01, 2.6273333e+01],\n",
    "       [5.7254095e+00, 2.5760990e+04, 9.6279999e+01, 3.4454166e+01],\n",
    "       [5.4324207e+00, 1.2948430e+04, 9.0654999e+01, 3.6110554e+01],\n",
    "       [5.7097182e+00, 8.0617100e+03, 8.5294998e+01, 2.3565277e+01],\n",
    "       [5.6727929e+00, 1.2387530e+04, 9.2535004e+01, 2.4852501e+01],\n",
    "       [5.4024849e+00, 8.1778799e+03, 8.8980003e+01, 4.7656387e+01],\n",
    "       [5.5242515e+00, 1.9322131e+04, 7.9985001e+01, 4.6826668e+01],\n",
    "       [5.1234756e+00, 1.6099910e+04, 8.3794998e+01, 2.4853611e+01],\n",
    "       [5.8418040e+00, 6.7139800e+03, 8.3955002e+01, 2.4078611e+01],\n",
    "       [5.5151114e+00, 1.7712240e+04, 8.5815002e+01, 2.3572500e+01]])\n",
    "\n",
    "# Outcome: average heart rate, in beats per minute\n",
    "\n",
    "ytrain = np.array([[150., 146., 148., 152., 147., 152., 151., 144., 149., 146., 144.,\n",
    "       141., 151., 150., 140., 147., 133., 144., 129., 154., 146., 141.,\n",
    "       155., 151., 111., 138., 141., 151., 134., 150., 134., 150., 149.,\n",
    "       134., 140., 137., 141., 150., 129., 143.]])\n",
    "\n",
    "Xtest = np.array([[5.6516337e+00, 1.1277530e+04, 9.4644997e+01, 5.3126389e+01],\n",
    "       [5.9737158e+00, 2.8977260e+04, 9.4230003e+01, 2.0872499e+01],\n",
    "       [5.4094992e+00, 1.1285160e+04, 7.9794998e+01, 4.6364723e+01],\n",
    "       [5.3885121e+00, 1.9334391e+04, 8.2080002e+01, 2.2815277e+01],\n",
    "       [4.9500046e+00, 1.6110120e+04, 8.3410004e+01, 4.8843613e+01],\n",
    "       [5.9269800e+00, 8.0592202e+03, 9.9250000e+01, 2.7060556e+01],\n",
    "       [6.0496063e+00, 3.2190711e+04, 9.3800003e+01, 2.4073334e+01],\n",
    "       [6.6427526e+00, 9.8029502e+03, 8.5150002e+01, 4.4903057e+01],\n",
    "       [5.4112554e+00, 1.0247100e+04, 8.1955002e+01, 2.4426390e+01],\n",
    "       [5.5853438e+00, 2.2543590e+04, 8.4849998e+01, 2.3573610e+01],\n",
    "       [4.0709982e+00, 2.5134600e+03, 9.4324997e+01, 2.7191111e+01],\n",
    "       [5.9038849e+00, 9.6685303e+03, 8.8099998e+01, 2.3758333e+01],\n",
    "       [5.5315852e+00, 1.9787490e+04, 9.7684998e+01, 3.3159168e+01],\n",
    "       [5.1062093e+00, 1.2883740e+04, 7.9375000e+01, 5.9931667e+01],\n",
    "       [6.1591525e+00, 9.6694502e+03, 8.2260002e+01, 2.4936388e+01],\n",
    "       [5.4914880e+00, 1.2887790e+04, 9.7154999e+01, 5.1264168e+01]])\n",
    "\n",
    "ytest = np.array([[134., 144., 145., 142., 153., 130., 139., 122., 141., 140., 129.,\n",
    "       129., 142., 143., 122., 141.]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Q1 continued) **Do the following:**\n",
    "\n",
    "1. **Build a linear regresion model for the training data. Give the optimal parameter vector $\\mathbf{\\theta}$ below:**\n",
    "\n",
    "2. **Plot predicted heart rate against actual heart rate for the training set and the test set using these parameters.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place code to build regression model and draw plots here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (20 points)\n",
    "\n",
    "As it turns out, there is one outlier in the training data, when Matt's heart rate monitor was not fixed correctly against the skin, resulting in a strange average heart rate.\n",
    "\n",
    "**Do the following:**\n",
    "\n",
    "1. **Plot pace (column 0) against heart rate ($\\textbf{y}$) for the training data.**\n",
    "\n",
    "2. **Give the outlier point's data here and explain why it does not seem to be consistent with the other data.**\n",
    "\n",
    "3. **Build a new regression model without this point, and make a new plot of predicted versus actual heart rate for the training set and test set using the new parameters.**\n",
    "\n",
    "4. **Briefly discuss whether the result based on the \"cleaned\" dataset is better than the result on the original data set.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place code for plots and the new regression model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (20 points)\n",
    "\n",
    "Actually, the data in Questions 1 and 2 are not quite independent of each other, as they form a sequence. Performance in a sport improves with training over time.\n",
    "\n",
    "Perhaps we can model the effect of training on performance by adding a new variable to the data set that is the number of days since the training began.\n",
    "\n",
    "Create a new variable indicating the number of days that have passed since training began. Let's name this variable $x_5$, and let $x_4$ be the \"hours of rest since the last run\" variable (last column in the $\\texttt{X}$ data set). Let $x_5^{(0)} = 0$, and let\n",
    "\n",
    "$$x_5^{(i)} = \\frac{1}{24}\\sum_{j=1}^{i-1} x_4^{(i)}.$$ \n",
    "\n",
    "You can calculate this more easily using the recurrence\n",
    "\n",
    "$$x_5^{(i)} = x_5^{(i-1)} + \\frac{1}{24}x_4^{(i)}.$$ \n",
    "\n",
    "**Do the following:**\n",
    "\n",
    "1. **Add the new variable $x_5$ to your test and training datasets. Note that the test data are just a continuation of the series from the training data, so $x_5$ for the first entry in the test set should be $x_5$ for the last entry in the training set plus the number of rest hours for the first entry in the test set divided by 24.**\n",
    "\n",
    "2. **Build a new regression model using the augmented data set, give the optimal parameters $\\mathbf{\\theta}$ here, and show the scatter plot of predicted versus actual outcomes for the training set and test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place code to augment the data set and plot the results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "\n",
    "Next we consider a classification problem. We know that logistic regression is only capable of modeling linear classification boundaries. In this question, you will synthesize a data set that has a nonlinear classification boundary then show that we can obtain a good logistic regression classifier by transforming the data so that an appropriate classification boundary is linear in the new transformed inputs.\n",
    "\n",
    "**Do the following:**\n",
    "\n",
    "1. **Generate 100 data points for class 1 in which $x_1$ is sampled uniformly from the range [-3..3] and $x_2$ is sampled from a Gaussian with mean $x_1^2 + 2$ and standard deviation 1.0.**\n",
    "\n",
    "2. **Generate 100 data points for class 2 in which $x_1$ is sampled uniformly from the range [-3..3] and $x_2$ is sampled from a Gaussian with mean $x_1^2 + 5$ and standard deviation 1.0.**\n",
    "\n",
    "3. **Split the dataset into 80% test and 20% train, estimate a logistic regression model, and report the model's training set accuracy, test set accuracy, and optimal parameters here:**\n",
    "\n",
    "4. **Transform the data to contain five input variables: $x_1$, $x_2$, $x_1^2$, $x_2^2$, and $x_1x_2$. Build a new logistic regression model, report its training and test set accuracy, and optimal parameters here:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place code to generate the data, estimate the models, and report accuracy here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Suppose you were interested in predicting the number of traffic fatalities that occur at a given traffic intersection based on various factors that might indicate the level of danger at that intersection: number of lanes, speed limit, types and number of businesses close to the intersection, curvature of the roads leading to the intersection, number of people that live in the surrounding area, and so on.\n",
    "\n",
    "Imagine that you obtain monthly fatality counts for 500 intersections in Bangkok and also obtain the necessary input data on the characteristics of the intersections then start to model.\n",
    "\n",
    "The standard linear regression model would consider the outcome (the number of traffic fatalities per month) as a Gaussian random variable with a mean of $\\mathbf{\\theta}^T\\mathbf{x}$. But that might not be the best approach for this problem.\n",
    "\n",
    "For example, you might consider the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution).\n",
    "\n",
    "**Do the following.**\n",
    "\n",
    "1. **Read briefly about the Poisson distribution and explain here why it would be a better model of the outcome (number of traffic fatalities per month at a particular intersection) than a Gaussian.**\n",
    "\n",
    "2. **Noting that the Poisson distribution is a member of the exponential family, explain in general how you could use the GLM approach to come up with a model that predicts the fatality rate to be a Poisson random variable with mean** $\\lambda = \\exp(\\mathbf{\\theta}^T\\textbf{x})$. **(Note that the exponential here is just to convert the linear combination of inputs, which could be positive or negative, to a strictly positive value.)**\n",
    "\n",
    "Note that for part 2, *you do not need to derive any equations*! Just explain what steps you would take to obtain a good machine learning algorithm for this problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
