{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_regression(x0, X, Y, tau):\n",
    "    # add bias term\n",
    "    x0 = np.r_[1.0, x0]    \n",
    "    X = np.c_[np.ones(len(X)), X]\n",
    "    \n",
    "    # fit model: normal equations with kernel      \n",
    "    w = radial_kernel(x0, X, tau) \n",
    "   \n",
    "    m = len(X)\n",
    "    xw = X.T * w\n",
    "    beta = np.linalg.pinv(xw @ X) @ xw @ Y\n",
    "    \n",
    "    gradient = Gradient(beta, X, Y, xw, m)\n",
    "    # predict value\n",
    "    return x0 @ beta, beta, gradient\n",
    "\n",
    "\n",
    "def Cost(theta,x,Y,W,m):\n",
    "    cost = ((x @ theta-Y)**2)\n",
    "    return cost/m\n",
    "\n",
    "def Gradient(theta,x,Y,W,m):\n",
    "    gradient = (((x @ theta-Y) @ x)/m)\n",
    "    return gradient\n",
    "\n",
    "def Accuracy(theta,X, Y):\n",
    "    #score_predicted = 1-((y-y_gd)**2).sum()/((y-y.mean())**2).sum()    \n",
    "    return ((Y - X @ theta)**2).sum()/((Y - Y.mean())**2).sum()\n",
    "\n",
    "def cost_w(w,y,h_theta):\n",
    "    return np.sum(w*(y-h_theta))\n",
    "\n",
    "def radial_kernel(x0, X, tau):\n",
    "    w =  np.exp(np.sum((X - x0) ** 2, axis=1) / (-2 * tau * tau))\n",
    "    #w_1 = np.exp(-np.dot((x0 - X).T, (x0-X))/2*tau**2)    \n",
    "    return w\n",
    "\n",
    "def polynomial(x,degree):\n",
    "    #poly = np.zeros((1,2))\n",
    "    poly = []\n",
    "    for i in np.arange(1,degree+1,1):\n",
    "        poly.append(x**i)\n",
    "        #poly = np.concatenate((poly,x**(i)), axis = 1)\n",
    "    return poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 300\n",
    "\n",
    "\n",
    "# generate dataset\n",
    "#X = np.sort(np.random.uniform(0, 6,m))\n",
    "X = np.linspace(0,6,m)\n",
    "Y = np.sin(X*np.pi/2) + np.random.normal(0,.25,m)\n",
    "\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "idx = np.arange(0,len(X), 1)\n",
    "np.random.shuffle(idx)\n",
    "idx_train = np.sort(idx[:int(len(idx)*.8)])\n",
    "idx_test =np.sort(idx[:int(len(idx)*.2)])\n",
    "\n",
    "X_train = X[idx_train]\n",
    "X_test = X[idx_test]\n",
    "Y_train = Y[idx_train]\n",
    "Y_test = Y[idx_test]\n",
    "\n",
    "X_train_fit  = np.array(polynomial(X_train, 1)).T\n",
    "X_test_fit  = np.array(polynomial(X_test, 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lwr(X, Y, tau):\n",
    "    prediction_arr = []\n",
    "   \n",
    "    gradient_arr = []\n",
    "    #accuracy = []\n",
    "    theta_arr = []\n",
    "    #choose data points at regular intervals\n",
    "    \n",
    "    ix = np.arange(0, len(X_test),1)    \n",
    "    for i in ix:\n",
    "       prediction, beta, gradient = local_regression(X_test[i],X, Y, tau)\n",
    "       prediction_arr.append(prediction)       \n",
    "       gradient_arr.append(gradient)\n",
    "       #accuracy.append(local_regression(X[i],X, Y, tau)[2])\n",
    "       theta_arr.append(beta)\n",
    "    return prediction_arr,theta_arr, gradient_arr      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1, theta1, gradient1 = compute_lwr(X_train_fit,Y_train,10)\n",
    "prediction2, theta2, gradient2 = compute_lwr(X_train_fit,Y_train,1)\n",
    "prediction3, theta3, gradient3 = compute_lwr(X_train_fit,Y_train,.2)\n",
    "prediction4, theta4, gradient4 = compute_lwr(X_train_fit,Y_train,.01)   \n",
    "\n",
    "tau = .05\n",
    "prediction_arr_train = []\n",
    "prediction_arr_test = []\n",
    "theta_arr_train = []\n",
    "tau_arr_train = []\n",
    "gradient_arr_train = []\n",
    "\n",
    "while tau < 2.0:\n",
    "    prediction, theta, gradient = compute_lwr(X_train_fit,Y_train,tau)\n",
    "    gradient_arr_train.append(gradient)\n",
    "    theta_arr_train.append(theta)\n",
    "    prediction_arr_train.append(np.sum(prediction))   \n",
    "    tau_arr_train.append(tau)    \n",
    "    tau = tau + tau*.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1, ax = plt.subplots(2,2)\n",
    "# fig1.set_figheight(5)\n",
    "# fig1.set_figwidth(10)\n",
    "# fig1.subplots_adjust(left=.2, bottom=None, right=None, top=None, wspace=.4, hspace=.4)\n",
    "# plt1 = plt.subplot(2,2,1)\n",
    "# plt2 = plt.subplot(2,2,2)\n",
    "# plt3 = plt.subplot(2,2,3)\n",
    "# plt4 = plt.subplot(2,2,4)\n",
    "\n",
    "# plt1.plot(X,Y,'c.')\n",
    "\n",
    "# plt1.plot(X_test,prediction1,'g.')\n",
    "# plt1.set_title('Prediction 1, Tau = 10')\n",
    "# plt1.set_xlabel('units')\n",
    "# plt1.set_ylabel('Frequency')\n",
    "# plt1.grid(axis='both', alpha=.25)\n",
    "\n",
    "# plt2.plot(X,Y,'c.')\n",
    "# plt2.set_title('Prediction 2, Tau = 1')\n",
    "# plt2.plot(X_test,prediction2,'g.')\n",
    "# plt2.set_xlabel('units')\n",
    "# plt2.set_ylabel('Frequency')\n",
    "# plt2.grid(axis='both', alpha=.25)\n",
    "\n",
    "# plt3.plot(X,Y,'c.')\n",
    "# plt3.set_title('Prediction 3, Tau = .2')\n",
    "# plt3.plot(X_test,prediction3,'g.')\n",
    "# plt3.set_xlabel('units')\n",
    "# plt3.set_ylabel('Frequency')\n",
    "# plt3.grid(axis='both', alpha=.25)\n",
    "\n",
    "\n",
    "# plt4.plot(X,Y,'c.')\n",
    "# plt4.set_title('Prediction 4, Tau = .01')\n",
    "# plt4.plot(X_test,prediction4,'g.')\n",
    "# plt4.set_xlabel('units')\n",
    "# plt4.set_ylabel('Frequency')\n",
    "# plt4.grid(axis='both', alpha=.25)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fig3 = plt.figure()\n",
    "# ax = plt.axes()\n",
    "# plt.title('Tau vs prediction error')\n",
    "# plt.xlabel('Tau')\n",
    "# plt.grid(axis='both', alpha=.25)\n",
    "# plt.plot(tau_arr_train,prediction_arr_train,'g-')\n",
    "# plt.show()\n",
    "\n",
    "tau_optimal = tau_arr_train[np.argmin(prediction_arr_train)]\n",
    "prediction5, theta5, gradient5 = compute_lwr(X_train_fit,Y_train,tau_optimal)\n",
    "# prediction_arr_train\n",
    "# a = np.array([0,1,2,7,-4])\n",
    "# np.argmin(a)\n",
    "# fig4 = plt.figure()\n",
    "# ax = plt.axes()\n",
    "# plt.title('Locally weighted Linear Regression')\n",
    "# plt.grid(axis='both', alpha=.25)\n",
    "# plt.plot(X_train,Y_train,'c.')\n",
    "# plt.plot(X_test,prediction5,'b.')\n",
    "# plt.show()\n",
    "# print('Optimal value of Tau ', tau_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
