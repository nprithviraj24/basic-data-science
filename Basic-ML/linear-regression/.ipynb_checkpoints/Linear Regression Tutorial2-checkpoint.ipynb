{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick linear regression tutorial with numpy\n",
    "\n",
    "This is a quick tutorial in doing linear regression models\n",
    "with numpy and checking the correctness of the result of\n",
    "a machine learning experiment.\n",
    "\n",
    "For any supervised learning experiment, we need\n",
    "\n",
    "1. A data set with matched input-output pairs $\\{ (\\mathbf{x}^{(1)}, y^{(1)}), \\ldots, (\\mathbf{x}^{(m)}, y^{(m)}) \\}$ ;\n",
    "2. A model (a mathematical equation for the hypothesis $h_{\\mathbf{\\theta}}(\\mathbf{x})$;\n",
    "3. A loss function ${\\cal L}(\\mathbf{\\theta}, \\mathtt{X}, \\mathbf{y})$.\n",
    "\n",
    "In the case of linear regression, the model is $$ h_{\\mathbf{\\theta}}(\\mathbf{x}) = \\theta_0 + \\theta_1 x_1 + \\cdots + \\theta_n x_n . $$\n",
    "and the loss function is $$ {\\cal L}(\\mathbf{\\theta}, \\mathtt{X}, \\mathbf{y}) = \\frac{1}{2} \\sum_{i=1}^m \\left(h_{\\mathbf{\\theta}}(\\mathbf{x}^{(i)})-y^{(i)}\\right)^2 .$$\n",
    "If we arrange the data into matrices as\n",
    "$$\\mathtt{X} = \\begin{bmatrix} 1 & x_1^{(1)} & \\cdots & x_n^{(1)} \\\\\n",
    "                               \\vdots & \\vdots & & \\vdots \\\\\n",
    "                               1 & x_1^{(m)} & \\cdots & x_n^{(m)} \\end{bmatrix}, \\;\\;\\;\\;\n",
    "                               \\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}, $$\n",
    "then the optimal parameters are\n",
    "$$\\mathbf{\\theta}^* = (\\mathtt{X}^{\\top} \\mathtt{X})^{-1} \\mathtt{X}^{\\top} \\mathbf{y} $$\n",
    "(the normal equations).\n",
    "\n",
    "In the code below, we synthesize a sample data set comprising $\\mathtt{X}$ and $\\mathbf{y}$, calculate\n",
    "$\\mathbf{\\theta}^*$, compare the loss based on the optimal and ground truth parameters, then verify that\n",
    "$\\mathbf{\\theta}^*$ is approximately a minimum of the loss function using finite differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters: -119.438905, 1.107040\n",
      "Loss with ground truth theta: 50262.681165\n",
      "Loss with estimated theta: 49429.429425\n",
      "Gradient estimate: 0.000073, 0.271903\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ground truth parameters\n",
    "\n",
    "theta0 = -100\n",
    "theta1 = 1\n",
    "sigma = 10\n",
    "\n",
    "# Generate training dataset using ground truth\n",
    "\n",
    "m = 100\n",
    "\n",
    "# X: m samples from a Gaussian with mean 160 and standard deviation of 20\n",
    "\n",
    "X = np.matrix(np.random.normal(160, 20, m)).T\n",
    "X = np.concatenate([np.ones([m,1]),X],1)\n",
    "\n",
    "# y: m samples from a Gaussian with mean theta0 + theta1 x, std of sigma\n",
    "\n",
    "theta = np.matrix([ theta0, theta1 ]).T\n",
    "y = X * theta + np.random.normal(0, 20, [m,1])\n",
    "\n",
    "# Estimate a linear model\n",
    "\n",
    "theta_est = np.linalg.inv(X.T*X) * X.T * y\n",
    "\n",
    "print('Estimated parameters: %f, %f' % (theta_est[0], theta_est[1]))\n",
    "\n",
    "def loss(X, y, theta):\n",
    "    error = y - X * theta\n",
    "    error = error.T * error\n",
    "    return error\n",
    "    \n",
    "lgt = loss(X, y, theta)\n",
    "print(\"Loss with ground truth theta: %f\" % lgt)\n",
    "lest = loss(X, y, theta_est)\n",
    "print(\"Loss with estimated theta: %f\" % lest)\n",
    "\n",
    "# Verify result using finite differences\n",
    "\n",
    "deltaTheta = 0.0000001\n",
    "\n",
    "# Parameter theta0\n",
    "thetaNew = theta_est + np.matrix([ deltaTheta, 0 ]).T\n",
    "lnew0 = loss(X, y, thetaNew)\n",
    "grad0est = (lnew0 - lest) / deltaTheta\n",
    "\n",
    "# Parameter theta1\n",
    "thetaNew = theta_est + np.matrix([ 0, deltaTheta ]).T\n",
    "lnew1 = loss(X, y, thetaNew)\n",
    "grad1est = (lnew1 - lest) / deltaTheta\n",
    "\n",
    "print('Gradient estimate: %f, %f' % (grad0est, grad1est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (100,3) and (2,1) not aligned: 3 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5a7d4f01bb30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#X*theta already giving a mean value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Estimate a linear model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__rmul__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (100,3) and (2,1) not aligned: 3 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ground truth parameters\n",
    "\n",
    "theta0 = -115\n",
    "theta1 = 1\n",
    "theta2 = 0.5\n",
    "sigma_x1 = 20\n",
    "sigma_x2 = 15\n",
    "sigma_y = 20\n",
    "\n",
    "# Generate training dataset using ground truth\n",
    "\n",
    "m = 100\n",
    "\n",
    "# X: m samples from a Gaussian with mean 160 and standard deviation of 20\n",
    "\n",
    "X1 = np.matrix(np.random.normal(160, sigma_x1, m)).T\n",
    "X2 = np.matrix(np.random.normal(30, sigma_x2, m)).T\n",
    "X = np.concatenate([np.ones([m,1]),X1, X2],1)\n",
    "\n",
    "# y: m samples from a Gaussian with mean theta0 + theta1 x, std of sigma\n",
    "\n",
    "theta = np.matrix([ theta0, theta1 ]).T\n",
    "\n",
    "#X*theta already giving a mean value\n",
    "y = X * theta + np.random.normal(0, 20, [m,1])\n",
    "\n",
    "# Estimate a linear model\n",
    "# the below equation will be same for single or multivariate variables, but X.T * X must be invertible.\n",
    "theta_est = np.linalg.inv(X.T*X) * X.T * y\n",
    "\n",
    "print('Estimated parameters: %f, %f, %f' % (theta_est[0], theta_est[1],  theta_est[2]))\n",
    "\n",
    "def loss(X, y, theta):\n",
    "    error = y - X * theta\n",
    "    error = error.T * error\n",
    "    return error\n",
    "    \n",
    "lgt = loss(X, y, theta)\n",
    "print(\"Loss with ground truth theta: %f\" % lgt)\n",
    "lest = loss(X, y, theta_est)\n",
    "print(\"Loss with estimated theta: %f\" % lest)\n",
    "\n",
    "# Verify result using finite differences\n",
    "\n",
    "deltaTheta = 0.0000001\n",
    "\n",
    "# Parameter theta0\n",
    "thetaNew = theta_est + np.matrix([ deltaTheta, 0 ]).T\n",
    "lnew0 = loss(X, y, thetaNew)\n",
    "grad0est = (lnew0 - lest) / deltaTheta\n",
    "\n",
    "# Parameter theta1\n",
    "thetaNew = theta_est + np.matrix([ 0, deltaTheta ]).T\n",
    "lnew1 = loss(X, y, thetaNew)\n",
    "grad1est = (lnew1 - lest) / deltaTheta\n",
    "\n",
    "print('Gradient estimate: %f, %f' % (grad0est, grad1est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
