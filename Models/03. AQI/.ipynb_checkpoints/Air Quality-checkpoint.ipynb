{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-572e7fc715c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pickle\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "# Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to perform data standardization \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import classes for ML Models\n",
    "from sklearn.linear_model import Ridge  ## Linear Regression + L2 regularization\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "\n",
    "# To save the final model on disk\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis, Data Preprocessing, and data Visualization\n",
    "\n",
    "Reading CSV file data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wbengal.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Displaying first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the all columns of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the Unnamed: 0 and data attribute is not useful for us for the prediction. Also state for which we are doing is the West Bengal which is same throughout the data. So we will be dorpping all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'date', 'state'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see location, type and the AQI_range is the only object data type. Rest all are the float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AQI_Range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying unique locations\n",
    "print(df['location'].nunique())\n",
    "df['location'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total 17 unique locations in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying unique type\n",
    "print(df['type'].nunique())\n",
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As you can see the 'Industrial Area', 'Industrial', and 'Industrial Areas' are same. So we can assign the same labels to them. This way it will reduce our unique values of location.\n",
    "* Also 'Residential', 'Residential, Rural and other Areas', 'Residential and others' can be combine into 1 group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].replace(['Industrial Area', 'Industrial Areas', 'Industrial'], 'Industrial Area', inplace = True)\n",
    "df['type'].replace(['Residential', 'Residential, Rural and other Areas', 'Residential and others'], 'Residential',\n",
    "                   inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying unique type\n",
    "print(df['type'].nunique())\n",
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "ax = sns.countplot(data = df, x = 'AQI_Range')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.title(\"Count AQI Ranges\")\n",
    "plt.xlabel(\"AQI Range\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countplot by each location of West Bengal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "ax = sns.countplot(data = df, x = 'location')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.title(\"Count of each location\")\n",
    "plt.xlabel(\"Locations\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barplot of AQI for each location in WB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "ax = sns.barplot(data = df, x = 'location', y = \"AQI\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.title(\"Barplot of AQI by each location in WB\")\n",
    "plt.xlabel(\"Locations\")\n",
    "plt.ylabel(\"AQI Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the above plot the DURAGAPUR (WB) location has the highest AQI Value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barplot of AQI by each type in WB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "ax = sns.barplot(data = df, x = 'type', y = \"AQI\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.title(\"Barplot of AQI by each type in WB\")\n",
    "plt.xlabel(\"Type\")\n",
    "plt.ylabel(\"AQI Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest AQI value is due to the Industrial type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.fillna('NA').groupby(['location','type'])['AQI'].sum().groupby(['location','type']).max().sort_values().groupby(['location']).sum().sort_values(ascending=False)\n",
    "top_count = pd.DataFrame(df_plot)\n",
    "top_count1 = pd.DataFrame(df_plot.head(17))\n",
    "fig_reg = px.bar(top_count1,x=top_count1.index, y='AQI',color='AQI')\n",
    "fig_reg.update_layout(\n",
    "    title=\"AQI Values by each location in west bengal\",\n",
    "    xaxis_title=\" Locations\",\n",
    "    yaxis_title=\"AQI Values \",\n",
    "    )\n",
    "fig_reg.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.fillna('NA').groupby(['location','type'])['AQI'].sum().groupby(['location','type']).max().sort_values().groupby(['type']).sum().sort_values(ascending=False)\n",
    "top_count = pd.DataFrame(df_plot)\n",
    "top_count1 = pd.DataFrame(df_plot.head(17))\n",
    "fig_reg = px.bar(top_count1,x=top_count1.index, y='AQI',color='AQI')\n",
    "fig_reg.update_layout(\n",
    "    title=\"AQI Values by each type in west bengal\",\n",
    "    xaxis_title=\" Type\",\n",
    "    yaxis_title=\"AQI Values \",\n",
    "    )\n",
    "fig_reg.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting AQI Range and AQI values for the randomly 2 to 3 location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort=df[df[\"location\"]==\"HALDIA\"].sort_values(by=[\"AQI\"],ascending=False)\n",
    "#sort_fat=df[df[\"location\"]==\"HALDIA\"].sort_values(by=[\"Fatalities\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(sort, x=\"AQI\", y=\"AQI_Range\",color='AQI_Range', title='AQI Range and AQI values by HALDIA location')\n",
    "fig.update_layout( xaxis_title=\" AQI \",yaxis_title=\" AQI Range\")\n",
    "\n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the the AQI values less than 50 is havig good AQI Range. For the Hazardous AQI Range the AQI values are greater than 400. Similarly for the others you can observe from the above plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort=df[df[\"location\"]==\"CALCUTTA\"].sort_values(by=[\"AQI\"],ascending=False)\n",
    "fig = px.line(sort, x=\"AQI\", y=\"AQI_Range\",color='AQI_Range', title='AQI Range and AQI values by CALCUTTA location')\n",
    "fig.update_layout( xaxis_title=\" AQI \",yaxis_title=\" AQI Range\")\n",
    "\n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CALCUTTA location the AQI values can go more than 800 for the Hazardous AQI Range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort=df[df[\"location\"]==\"ULUBERIA\"].sort_values(by=[\"AQI\"],ascending=False)\n",
    "fig = px.line(sort, x=\"AQI\", y=\"AQI_Range\",color='AQI_Range', title='AQI Range and AQI values by ULUBERIA location')\n",
    "fig.update_layout( xaxis_title=\" AQI \",yaxis_title=\" AQI Range\")\n",
    "\n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ULUBERIA location the AQI Range is poor throughout the all the values of the AQI. The AQI values are not also exceeding more than the 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of so2 and no2 values by each location in west bengal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort=df.sort_values(\"AQI\",ascending=False)\n",
    "fig = px.scatter(sort, x=\"so2\", y=\"no2\",color='location', title='so2 and no2 values by each location in west bengal')\n",
    "fig.update_layout( xaxis_title=\" so2 values \",yaxis_title=\"no2 values\")\n",
    "\n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see for each location the most of the so2 and no2 values are below 150."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of so2 and no2 values by each type in west bengal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort=df.sort_values(\"AQI\",ascending=False)\n",
    "fig = px.scatter(sort, x=\"so2\", y=\"no2\",color='type', title='so2 and no2 values by each type in west bengal')\n",
    "fig.update_layout( xaxis_title=\" so2 values \",yaxis_title=\"no2 values\")\n",
    "\n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the values of so2 and no2 are due to the Industrial Area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort=df.sort_values(\"AQI\",ascending=False)\n",
    "fig = px.line(sort, x=\"AQI\", y=\"AQI_Range\",color='location', title='AQI Range and AQI values by each location in west bengal')\n",
    "fig.update_layout( xaxis_title=\" AQI values \",yaxis_title=\"AQI Range\")\n",
    "\n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for the null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding\n",
    "\n",
    "There is no value mission in our dataset. So all the values are filled in the dataset. As we have seen above the AQI Range, location and type are the categorical features. So we need to convert it into the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_en1 = LabelEncoder()\n",
    "df['type'] = label_en1.fit_transform(df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_en1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_en1.transform(['Industrial Area', 'RIRUO', 'Residential'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_en2 = LabelEncoder()\n",
    "df['location'] = label_en2.fit_transform(df['location'])\n",
    "print(label_en2.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_en2.transform(['ASANSOL', 'BARRACKPORE', 'BARUIPUR', 'CALCUTTA', 'DANKUNI', 'DURGAPUR',\n",
    "                     'DURGAPUR (WB)', 'HALDIA', 'HOWRAH', 'KALYANI', 'KOLKATA', 'MALDAH', 'RANIGANJ',\n",
    "                     'SANKRAIL', 'SILIGURI', 'SOUTH SUBURBAN', 'ULUBERIA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_en3 = LabelEncoder()\n",
    "df['AQI_Range'] = label_en3.fit_transform(df['AQI_Range'])\n",
    "print(label_en3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_en3.transform(['Good', 'Hazardous', 'Moderate', 'Poor', 'Unhealthy', 'Very unhealthy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will confirm that all the features contains now numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all the 3 encoders to the disk for the future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('Type_encoder.pkl', 'wb')\n",
    "pickle.dump(label_en1, output)\n",
    "output.close()\n",
    "\n",
    "output = open('Location_encoder.pkl', 'wb')\n",
    "pickle.dump(label_en2, output)\n",
    "output.close()\n",
    "\n",
    "output = open('AQI_Range_encoder.pkl', 'wb')\n",
    "pickle.dump(label_en3, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the model saved to disk by again loading it. This is just for the cross verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = open('Type_encoder.pkl', 'rb')\n",
    "label = pickle.load(pkl_file) \n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.transform(['Industrial Area', 'RIRUO', 'Residential'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df['AQI']\n",
    "y2 = df['AQI_Range']\n",
    "X = df.drop(['AQI', 'AQI_Range'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data standardization\n",
    "* In Data Standardization we perform zero mean centring and unit scaling; i.e. we make the mean of all the features as zero and the standard deviation as 1.\n",
    "* Thus we use **mean** and **standard deviation** of each feature.\n",
    "* It is very important to save the **mean** and **standard deviation** for each of the feature from the **training set**, because we use the same mean and standard deviation in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StandardScaler()\n",
    "X = a.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test split\n",
    "\n",
    "As we have to developed the model to predict the 2 outcome so we will build the separate model for each outcome and accordingly also do the splitting of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test sets: 80-20\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X1_train.shape, X1_test.shape, y1_train.shape, y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test sets: 80-20\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X2_train.shape, X2_test.shape, y2_train.shape, y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Models for AQI values (Regression problem).\n",
    "\n",
    "##### 1. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge1 = Ridge()\n",
    "ridge1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Test results\n",
    "y_pred = ridge1.predict(X1_test)\n",
    "\n",
    "\n",
    "print(\"Validation Results for Ridge Regression:\")\n",
    "print(\"*******************************\")\n",
    "print(\"Root mean squared error: \", sqrt(mse(y1_test, y_pred)))\n",
    "print(\"R-squared: \", r2_score(y1_test, y_pred))\n",
    "print(\"Mean Absolute Error: \", mae(y1_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random1 = RandomForestRegressor()\n",
    "random1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Test results\n",
    "y_pred = random1.predict(X1_test)\n",
    "\n",
    "\n",
    "print(\"Validation Results for Random Forest Regression:\")\n",
    "print(\"*******************************\")\n",
    "print(\"Root mean squared error: \", sqrt(mse(y1_test, y_pred)))\n",
    "print(\"R-squared: \", r2_score(y1_test, y_pred))\n",
    "print(\"Mean Absolute Error: \", mae(y1_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBRegressor(n_estimators=1000)\n",
    "xgb1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Test results\n",
    "y_pred = xgb1.predict(X1_test)\n",
    "\n",
    "\n",
    "print(\"Validation Results for Xgboost Regression:\")\n",
    "print(\"*******************************\")\n",
    "print(\"Root mean squared error: \", sqrt(mse(y1_test, y_pred)))\n",
    "print(\"R-squared: \", r2_score(y1_test, y_pred))\n",
    "print(\"Mean Absolute Error: \", mae(y1_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the preformance of the 3 models we can say that the XGBoost has performed very well. So saving the model to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb1, 'AQI_model.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Models for AQI Range (Classification problem).\n",
    "\n",
    "##### 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = knn.score(X2_test, y2_test)\n",
    "print(\"accuracy = \",accuracy * 100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y2_test,y_pred).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting confusion matrix with proper labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y2_test,y_pred)\n",
    "plot_confusion_matrix(cm, figsize = (10, 5 ))\n",
    "plt.xticks(range(6), ['Good', 'Hazardous', 'Moderate', 'Poor', 'Unhealthy', 'Very unhealthy'], fontsize=16, rotation = 90)\n",
    "plt.yticks(range(6), ['Good', 'Hazardous', 'Moderate', 'Poor', 'Unhealthy', 'Very unhealthy'], fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y2_test,y_pred).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y2_test,y_pred)\n",
    "plot_confusion_matrix(cm, figsize = (10, 5 ))\n",
    "plt.xticks(range(6), ['Good', 'Hazardous', 'Moderate', 'Poor', 'Unhealthy', 'Very unhealthy'], fontsize=16, rotation = 90)\n",
    "plt.yticks(range(6), ['Good', 'Hazardous', 'Moderate', 'Poor', 'Unhealthy', 'Very unhealthy'], fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=0)\n",
    "gb.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y2_test,y_pred).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y2_test,y_pred)\n",
    "plot_confusion_matrix(cm, figsize = (10, 5 ))\n",
    "plt.xticks(range(6), ['Good', 'Hazardous', 'Moderate', 'Poor', 'Unhealthy', 'Very unhealthy'], fontsize=16, rotation = 90)\n",
    "plt.yticks(range(6), ['Good', 'Hazardous', 'Moderate', 'Poor', 'Unhealthy', 'Very unhealthy'], fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the confusion matrix we can say that the gradient boosting has performed well. So we will save it on the disk for the future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gb, 'AQI_Range_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
